@ARTICLE{10876115,
  author={Kina, Erol},
  journal={IEEE Access}, 
  title={TLEABLCNN: Brain and Alzheimer’s Disease Detection Using Attention-Based Explainable Deep Learning and SMOTE Using Imbalanced Brain MRI}, 
  year={2025},
  volume={13},
  number={},
  pages={27670-27683},
  abstract={Alzheimer’s disease (AD) is one of the primary causes of dementia. It degenerates the brain and reduces the activity of individuals by disrupting their memory and physiological functions. A comprehensive examination of specific brain tissue is required in order to accurately diagnose a brain condition using magnetic resonance imaging. The main aim of this research was to develop a rapid and effective technique for detecting healthy persons before the onset of brain tumours, including AD, pituitary tumours, gliomas, and meningiomas. This work presents a lightweight convolutional architecture based on EfficientNet with a Squeeze Attention Block using transfer learning. The proposed approach used lightweight layers with an L2 regularizer, global pooling (2D), and batch normalisation to construct the model, including two dropout layers. This paper utilises the synthetic minority oversampling approach to address the issues of overfitting and imbalanced samples by balancing two significantly imbalanced MRI datasets. We evaluated the efficacy of the minority strategy by doing experiments on both the training set and the entire dataset. The proposed model demonstrates high efficiency, with the risk of overfitting mitigated by applying SMOTE solely to the training data, while the test and validation datasets remain unaffected. The effectiveness of the proposed approach was evaluated using several performance measures and compared with previous published research. We evaluated the proposed approach for explainability via gradient-weighted class activation mapping to comprehend the model’s behaviour and its predictions. The proposed framework offers advantages over existing models in terms of computing efficiency, explainability, generalization, and clinical significance.},
  keywords={Diseases;Alzheimer's disease;Magnetic resonance imaging;Brain modeling;Tumors;Deep learning;Accuracy;Training;Transfer learning;Convolutional neural networks;Brain tumor;Alzheimer’s disease;deep learning;machine learning;SMOTE;XAI},
  doi={10.1109/ACCESS.2025.3539550},
  ISSN={2169-3536},
  month={},}@ARTICLE{10750189,
  author={Kim, Dohyun and Park, Jinseok and Choi, Hojin and Ryu, Hokyoung and Loeser, Martin and Seo, Kyoungwon},
  journal={IEEE Access}, 
  title={Early Detection of Patients With Mild Cognitive Impairment Through EEG-SSVEP-Based Machine Learning Model}, 
  year={2024},
  volume={12},
  number={},
  pages={172101-172114},
  abstract={Mild cognitive impairment (MCI) is a transitional stage from normal aging to Alzheimer’s disease (AD). Early detection of MCI is essential, as it offers a last opportunity for interventions to slow or prevent progression to AD. However, identifying effective biomarkers for screening remains challenging. While declines in perception and action often precede visible neurodegenerative changes, studies on visual pathway biomarkers for MCI detection are limited. In this study, we focused on electroencephalography with steady-state visual evoked potentials (EEG-SSVEP), known for its high-resolution, real-time monitoring of brain response to flicker stimulation, as a promising method for early MCI identification. We collected EEG-SSVEP data from 24 healthy controls and 25 MCI patients, extracting 166 EEG-SSVEP biomarkers, including lobe power ratio, lobe connectivity ratio, and band connectivity ratio, to assess the visual pathway’s dorsal and ventral streams related to cognitive decline. By employing a biomarker selection method, we identified six key EEG-SSVEP biomarkers as the most relevant for distinguishing between healthy controls and MCI patients. Subsequently, these six biomarkers were utilized to train a support vector machine for early detection of MCI. The results showed an accuracy rate of 95.69%, a sensitivity of 92.28%, and a specificity of 95.58%. This study offers valuable insights into enhancing the early detection of MCI by leveraging EEG-SSVEP data and machine learning to assess cognitive decline within the dorsal and ventral streams of the brain.},
  keywords={Visualization;Biomarkers;Machine learning;Electroencephalography;Brain modeling;Aging;Object recognition;Biological system modeling;Alzheimer's disease;Steady-state;Alzheimer’s disease;mild cognitive impairment;electroencephalography;steady-state visual evoked potential;intermittent photic stimulation;detection;machine learning},
  doi={10.1109/ACCESS.2024.3496079},
  ISSN={2169-3536},
  month={},}@ARTICLE{10613028,
  author={Pusparani, Yori and Lin, Chih-Yang and Jan, Yih-Kuen and Lin, Fu-Yu and Liau, Ben-Yi and Ardhianto, Peter and Furqon, Elvin Nur and Alex, John Sahaya Rani and Aparajeeta, Jeetashree and Lung, Chi-Wen},
  journal={IEEE Access}, 
  title={Deep Learning Applications in MRI-Based Detection of the Hippocampal Region for Alzheimer’s Diagnosis}, 
  year={2024},
  volume={12},
  number={},
  pages={103830-103838},
  abstract={The hippocampal region is one of the most affected brain areas observed as a landmark in Magnetic Resonance Imaging (MRI) images for Alzheimer’s disease (AD) diagnosis. The diminished alterations in the hippocampal and degeneration of cholinergic circuits have been conclusively correlated with a decline in memory and cognitive function. However, the hippocampal region may not appear as clearly defined as other brain regions, making it difficult for neurologists and researchers to identify by visual inspection. The application of deep learning models to pinpoint the hippocampal region was initially valued. We assessed the ability of a deep learning model, You Only Live Once (YOLO), to detect hippocampal regions in three MRI image views and categories. The Alzheimer’s Disease Neuroimaging Initiative-first (ADNI−1) dataset was used with 220 subjects in three categories using the three YOLO models. We obtained the YOLO performance for hippocampal region detection with accuracy in three views and categories. The average mean Average Precision (mAP) performance accuracy for YOLOv3 was 0.87, YOLOv4 was 0.85, and YOLOv5 was 0.96, respectively. The high accuracy of the detection of the hippocampal region was remarkable. We found that the sagittal view was higher than the axial and coronal views. Simultaneously, the Mild Cognitive Impairment (MCI) in the coronal view was lower among the three models. The results showed that YOLOv5 is a suitable model for detecting the hippocampal region in MRI images, and the sagittal view is the most reliable for detecting the hippocampal region in diagnosing AD. Our findings demonstrate the importance of detecting the hippocampal region to diagnose AD and accurately analyzing the hippocampal area within the region. The YOLOv5 model substantially affected performance metrics and interpretability across the three views and categories.},
  keywords={YOLO;Magnetic resonance imaging;Imaging;Alzheimer's disease;Feature extraction;Brain modeling;Accuracy;Landmark;hippocampal region;MRI image;YOLO;object detection},
  doi={10.1109/ACCESS.2024.3426085},
  ISSN={2169-3536},
  month={},}@ARTICLE{9218925,
  author={Alkenani, Ahmed H. and Li, Yuefeng and Xu, Yue and Zhang, Qing},
  journal={IEEE Access}, 
  title={Predicting Prodromal Dementia Using Linguistic Patterns and Deficits}, 
  year={2020},
  volume={8},
  number={},
  pages={193856-193873},
  abstract={Language deficiency is evident in the onset of several neurodegenerative disorders yet has barely been investigated when first occurs on the continuum of cognitive impairment for the purpose of early diagnoses. Alzheimer’s disease (AD) is a neurodegenerative pathology that develops years prior to clinical manifestations and typically preceded by prodromal stages such as Mild Cognitive Impairment (MCI). Currently, the manual diagnostic procedures of both types are time consuming, following certain clinical criteria and neuropsychological examinations. Our study aims to establish state-of-the-art performance in the automatic identification of different dementia etiologies, including AD, MCI, and Possible AD (PoAD), and to determine whether patients with initial cognitive declines exhibit language deficits through the analysis of language samples deduced with the cookie theft picture description task. Data was derived from the cookie theft picture corpus of DementiaBank, from which all language samples of the identified etiologies were used, with a random subsampling technique that handles the skewness of the classes. Several original lexical and syntactic (i.e., lexicosyntactic) features were introduced and used alongside previously established lexicosyntactics to train machine learning (ML) classifiers against these etiologies. Further, a statistical analysis was conducted to uncover the deficiency across these etiologies. Our models resulted in benchmarks for differentiating all the identified classes with accuracies ranging between 95 to 98% and corresponding F1 values falling between 94 and 98%. The statistical analysis of our lexicosyntactic biomarkers shows that linguistic deviations are associated with prodromal as well as advanced neurodegenerative pathologies, being greatly impacted as cognitive decline increases and suggesting that language biomarkers may aid the early diagnosis of these pathologies.},
  keywords={Dementia;Feature extraction;Support vector machines;Linguistics;Syntactics;Acoustics;Task analysis;Alzheimer’s disease;prodromal dementia;cognitive decline;clinical diagnosis;neurolinguistics;machine learning;prediction;feature selection},
  doi={10.1109/ACCESS.2020.3029907},
  ISSN={2169-3536},
  month={},}@ARTICLE{9796517,
  author={Zaina, Heba Soliman and Brahim Belhaouari, Samir and Stanko, Tanya and Gorovoy, Vladimir},
  journal={IEEE Access}, 
  title={An Exemplar Pyramid Feature Extraction Based Alzheimer Disease Classification Method}, 
  year={2022},
  volume={10},
  number={},
  pages={66511-66521},
  abstract={Dementia is a term used to describe a variety of symptoms related to cognitive impairment in which Alzheimer disease represents 60% – 70% of the cases. As of today, there is no cure for this disease and the only way to prevent any associated medical, economic, and financial impacts or losses is to detect the disease early and work closely with suspected patients to prevent any further progress. In this research, a methodology consisting of 4 modules is proposed: (1) preprocessing, exemplar pyramid along with bi-linear interpolation followed by (2) feature extraction using Gray Level Co-Occurrence Matrix and Local Binary Pattern then (3) concatenation of all extracted features and finally (4) classification of Alzheimer disease stage using deep learning, Multi-Layer Perceptron, in particular. Our proposed method was tested using the MPRAGE structural MRI dataset from Alzheimer Disease Neuro Imaging Initiative (ADNI), and it outperformed other techniques used in the literature review. An accuracy result of 89.80 was reported for multi-class classification of 4 stages of Alzheimer disease (Cognitive Normal, Early Mild Cognitive Impairment, Late Mild Cognitive Impairment and Alzheimer Disease) for both Gray Matter (GM) and White Matter (WM). In term of binary-class classification, we were able to achieve very good results using both GM and WM. By using GM, we were able to distinguish between CN vs EMCI, EMCI vs AD and LMCI vs AD with accuracy results of 96.43%, 90.91% and 95.24% respectively. And using WM, we were able to distinguish between CN vs LMCI with 100% accuracy and EMCI vs LMCI with 95.65% accuracy. While we achieved the same accuracy result of 96.15 using both WM and GM.},
  keywords={Feature extraction;Alzheimer's disease;Magnetic resonance imaging;Three-dimensional displays;Support vector machines;Nonlinear distortion;Cognitive normal (CN);early mild cognitive impairment (EMCI);late mild cognitive impairment (LMCI);alzheimer disease (AD);local binary pattern (LBP);gray level co-occurrence matrix (GLCM);multi-layer perceptron (MLP);exemplar pyramid},
  doi={10.1109/ACCESS.2022.3183185},
  ISSN={2169-3536},
  month={},}@ARTICLE{10125572,
  author={Guelib, Bouchra and Zarour, Karim and Hermessi, Haithem and Rayene, Bounab and Nawres, Khlifa},
  journal={IEEE Access}, 
  title={Same-Subject-Modalities-Interactions: A Novel Framework for MRI and PET Multi-Modality Fusion for Alzheimer’s Disease Classification}, 
  year={2023},
  volume={11},
  number={},
  pages={48715-48738},
  abstract={Alzheimer’s disease is a growing concern, and neuroimaging techniques such as Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET) scans are widely used to classify AD patients. While MRI captures structural information and measures brain atrophy, PET shows functional changes associated with neurological disorders, and both modalities have been proven to be AD biomarkers. However, combining MRI and PET in the same test without considering their inherent structural differences can result in a loss of important information. To address this issue, this paper proposes a novel machine learning framework for combining MRI and PET modalities and a new set of interactions known as Same-Subject-Modalities-Interactions (SSMI) to extract complementary information and new insights. The SSMI relation is derived from MRI and PET and subjected to PCA to construct the SSMI set, which is then concatenated with the other sets. The best set of features is selected and used for classification using Ridg-Classifier. Freesurfer is used to extract measures from 183 ADNI subjects (69 in the AD group and 114 in the CN group), and different classifiers are performed with train-test-split, cross-validation, and validation-set from ADNI-2/GO. The results showed high accuracy, precision, specificity, recall, F1-score, and AUC, with values of 98.94%, 98.27%, 97.10%, 100%, 99.13 and 98.55%, respectively, from ADNI and 98.75%, 98.48%, 93.75%, 100.0%, 99.23%, 96.80% from ADNI2/Go. These results are higher than those achieved by single-modality classification tasks and state-of-the-art approaches. Furthermore, the regions selected by Ridge Classifier are shown to be highly related to Alzheimer’s disease biomarkers.},
  keywords={Feature extraction;Magnetic resonance imaging;Positron emission tomography;Diseases;Machine learning;Computational modeling;Data mining;Multimodality;MRI;PET;fusion;machine learning;feature selection},
  doi={10.1109/ACCESS.2023.3276722},
  ISSN={2169-3536},
  month={},}@ARTICLE{9269972,
  author={Khagi, Bijen and Kwon, Goo-Rak},
  journal={IEEE Access}, 
  title={3D CNN Design for the Classification of Alzheimer’s Disease Using Brain MRI and PET}, 
  year={2020},
  volume={8},
  number={},
  pages={217830-217847},
  abstract={Attempt to diagnose Alzheimer’s disease (AD) using imaging modalities is one of the scopes of deep learning. While considering the theoretical background from past studies, we are trying to identify convolutional neural network (CNN) behaviors moving from 2D to 3D architecture. This study aims to explore the output from a variety of CNN models implemented in the MRI or/and PET classification tasks for AD prediction while trying to summarize its characteristics with a variety of parameters that are tuned and changed. There are many architectures available; however, we are testing a basic architecture with a change in the reception area based on the convolutional layer’s kernel size and its strides. The architecture has been categorized as converging, diverging, or equivalent if the filter kernel size is unchanged. This investigation studies a simple encoder based CNN with a sequential flow of features from low-level to high-level feature extraction. The idea is to present a diverging reception area by increasing the filter size and stride from a lower to a higher level. As a result, the feature redundancy is reduced and the trivial features keep on diminishing. The proposed architecture is referred to as ‘divNet’, and several experiments were performed to determine how effective the architecture is in terms of the consumed memory, the number of parameters, running time, classification error, and the generalization error. This study surveys several related experiments by changing the hyper-parameters setting, the architecture selection based on the depth and area of the reception feature, and the data size.},
  keywords={Magnetic resonance imaging;Three-dimensional displays;Feature extraction;Computer architecture;Neurons;Two dimensional displays;Brain;3D CNN;CNN architecture;Alzheimer’s disease;reception area;feature redundancy;data size;MRI classification},
  doi={10.1109/ACCESS.2020.3040486},
  ISSN={2169-3536},
  month={},}@ARTICLE{9099858,
  author={Jiménez-Mesa, Carmen and Illán, Ignacio Alvarez and Martín-Martín, Alberto and Castillo-Barnes, Diego and Martinez-Murcia, Francisco Jesus and Ramírez, Javier and Górriz, Juan M.},
  journal={IEEE Access}, 
  title={Optimized One vs One Approach in Multiclass Classification for Early Alzheimer’s Disease and Mild Cognitive Impairment Diagnosis}, 
  year={2020},
  volume={8},
  number={},
  pages={96981-96993},
  abstract={The detection of Alzheimer's Disease in its early stages is crucial for patient care and drugs development. Motivated by this fact, the neuroimaging community has extensively applied machine learning techniques to the early diagnosis problem with promising results. The organization of challenges has helped the community to address different raised problems and to standardize the approaches to the problem. In this work we use the data from international challenge for automated prediction of MCI from MRI data to address the multiclass classification problem. We propose a novel multiclass classification approach that addresses the outlier detection problem, uses pairwise t-test feature selection, project the selected features onto a Partial-Least-Squares multiclass subspace, and applies one-versus-one error correction output codes classification. The proposed method yields to an accuracy of 67% in the multiclass classification, outperforming all the proposals of the competition.},
  keywords={Feature extraction;Magnetic resonance imaging;Dementia;Standards;Neuroimaging;Machine learning;Alzheimer’s disease;CAD;error correcting output codes;mild cognitive impairment;multiclass classification;one versus one;partial least squares;random forests;support vector machines},
  doi={10.1109/ACCESS.2020.2997736},
  ISSN={2169-3536},
  month={},}@ARTICLE{9288747,
  author={Syed, Asif Hassan and Khan, Tabrej and Hassan, Atif and Alromema, Nashwan A. and Binsawad, Muhammad and Alsayed, Alhuseen Omar},
  journal={IEEE Access}, 
  title={An Ensemble-Learning Based Application to Predict the Earlier Stages of Alzheimer’s Disease (AD)}, 
  year={2020},
  volume={8},
  number={},
  pages={222126-222143},
  abstract={The fact that ensemble methods enhance the prediction performance. Therefore, we focused on developing a weighted ensemble method using a novel combination of Cerebrospinal Fluid (CSF) protein biomarkers to predict AD's earlier stages with greater accuracy than the state-of-the-art CSF protein biomarkers. In this regard, two feature selection methods, namely the Recursive Feature Elimination (RFE) and L1 regularization method were used to screen the most important subset of features for building a classification model using the Mild Cognitive Impairment (MCI) dataset. A novel combination of three biomarkers, namely Cystatin C, Matrix metalloproteinases (MMP10), and tau protein, was screened using the linear Support Vector Machine (SVM) and Logistic Regression (LR) classifier based RFE method. Two-tailed unpaired t-test analysis at a 5% significance level showed a significant difference between the mean levels of Cystatin C, MMP10, and tau protein between cognitive normal and cognitively impaired groups. An ensemble model using a weighted average of two best performing classifiers (LR and Linear SVM) was created using a novel subset of three most informative features. Our ensemble model's weighted average results performed significantly better than LR and Linear SVM base classifiers' performance. The Receiver Operating Characteristic Curve (ROC_AUC) and Area under Precision-Recall values (AUPR) of our proposed model were observed to be 0.9799 ± 0.055 0.9108 ± 0.015, respectively. The performance of our proposed weighted averaged ensemble model built using a novel combination of CSF protein biomarkers was significantly better (p <; 0.001) than models generated using different combinations of CSF protein biomarkers obtained from recent studies. An ensemble-learning based application was implemented and deployed at Heroku at https://appsalzheimer.herokuapp.com.},
  keywords={Biomarkers;Proteins;Biological system modeling;Predictive models;Alzheimer's disease;Feature extraction;Correlation;Mild cognitive impairment (MCI);cerebrospinal fluid (CSF) protein biomarkers;classification model;online prediction system},
  doi={10.1109/ACCESS.2020.3043715},
  ISSN={2169-3536},
  month={},}@ARTICLE{10580901,
  author={Addae, Sampson and Kim, Jungyoon and Smith, Arthur and Rajana, Priyanka and Kang, Misun},
  journal={IEEE Access}, 
  title={Smart Solutions for Detecting, Predicting, Monitoring, and Managing Dementia in the Elderly: A Survey}, 
  year={2024},
  volume={12},
  number={},
  pages={100026-100056},
  abstract={Dementia, a syndrome which is characterized by a decline in cognitive abilities such as memory, thinking, behavior, and the ability to perform daily living activities, is prevalent in people aged 60 and above. However, detecting it early enough can possibly slow its continuous degeneration and lessen the toll on families and caregivers alike. Due to its mortality within 10 years of onset as well as its enormous socioeconomic burden, there have been active efforts by researchers to find smart and innovative solutions for its early detection, prediction, monitoring, and management. These efforts are driven by the recent advancements in the Internet of Things (IoT), wearable technologies, and machine learning algorithms. The solutions are modeled around the modifiable risk factors of dementia. In this study, we conducted a survey of smart solutions developed or implemented to assist caregivers and clinicians in managing the health of these affected individuals. We then looked at the issues and limitations of these solutions, and argued that integrated solutions comprising wearable and non-wearable technologies modeled around multiple risk factors of dementia are necessary and should be the direction of future studies.},
  keywords={Temperature sensors;Biomedical monitoring;Temperature measurement;Monitoring;Alzheimer's disease;Wearable sensors;Intelligent sensors;Dementia;Dementia;wearable technology;Internet of Things (IoT);non-wearable technology;machine learning;activities of daily living (ADL);Alzheimer’s disease (AD);elderly},
  doi={10.1109/ACCESS.2024.3421966},
  ISSN={2169-3536},
  month={},}@ARTICLE{10105974,
  author={Turrisi, Rosanna and Squillario, Margherita and Abate, Giulia and Uberti, Daniela and Barla, Annalisa},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={An Overview of Data Integration in Neuroscience With Focus on Alzheimer's Disease}, 
  year={2024},
  volume={28},
  number={4},
  pages={1824-1835},
  abstract={This article represents the first attempt to provide an overview of how to face data integration as the result of a dialogue between neuroscientists and computer scientists. Indeed, data integration is fundamental for studying complex multifactorial diseases, such as the neurodegenerative diseases. This work aims at warning the readers of common pitfalls and critical issues in both medical and data science fields. In this context, we define a road map for data scientists when they first approach the issue of data integration in the biomedical domain, highlighting the challenges that inevitably emerge when dealing with heterogeneous, large-scale and noisy data and proposing possible solutions. Here, we discuss data collection and statistical analysis usually seen as parallel and independent processes, as cross-disciplinary activities. Finally, we provide an exemplary application of data integration to address Alzheimer's Disease (AD), which is the most common multifactorial form of dementia worldwide. We critically discuss the largest and most widely used datasets in AD, and demonstrate how the emergence of machine learning and deep learning methods has had a significant impact on disease's knowledge particularly in the perspective of an early AD diagnosis.},
  keywords={Data integration;Feature extraction;Data models;Data collection;Databases;Data mining;Data integrity;Multimodal data integration, machine and deep learning;multidisciplinary;neurodegenerative diseases;Alzheimer's disease},
  doi={10.1109/JBHI.2023.3268729},
  ISSN={2168-2208},
  month={April},}@ARTICLE{10963671,
  author={Thattil, Hansa J. and Arunkumar, M. N. and Antony, Francis},
  journal={IEEE Access}, 
  title={Enhanced Alzheimer’s Disease Prediction Through Integration of Protein-Protein Interaction Data and Meta-Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={68422-68438},
  abstract={Association between proteins and diseases have been widely studied to understand disease triggers and identify potential therapeutic targets. Deciphering the complexity of gene networks is crucial for understanding diseases. Node embedding offers a powerful approach, revealing latent patterns that can predict novel gene-disease associations. In this study, we applied a meta-learning approach to predict protein-disease associations with a focus on Alzheimer’s disease. Our approach utilized curated data from the Disease Gene Network Database (DisGeNET), a database of gene-disease associations, and protein-protein interaction data from the Search Tool for Retrieval of Interacting Genes/Proteins (STRING) dataset. We generated embeddings for Protein-Protein Interactions(PPI) using the node2vec algorithm, capturing interaction patterns in a low-dimensional space. HybridBoost, a two-layered model architecture, was then employed, with random forest and CatBoost classifiers in the first layer and CatBoost as the meta-learner in the second layer. Our model achieved an accuracy of 96% and with precision, recall, and F1 scores also outperforming individual models like random forest, support vector machine, AdaBoost, and CatBoost. These results demonstrate the effectiveness of the proposed meta-learning model in predicting protein-disease associations for Alzheimer’s disease.},
  keywords={Diseases;Proteins;Alzheimer's disease;Protein engineering;Feature extraction;Predictive models;Metalearning;Machine learning;Databases;Accuracy;Alzheimer’s disease;ADASYN;meta-learning;Node2vec;protein-protein interactions;protein-disease associations},
  doi={10.1109/ACCESS.2025.3560216},
  ISSN={2169-3536},
  month={},}@ARTICLE{10946883,
  author={Hossain, Al and Hani Konok, Umme and Tahsin, MD and Islam, Raihan Ul and Rifat Ahmmad Rashid, Mohammad and Shahadat Hossain, Mohammad and Andersson, Karl},
  journal={IEEE Access}, 
  title={A FixMatch Framework for Alzheimer’s Disease Classification: Exploring the Trade-Off Between Supervision and Performance}, 
  year={2025},
  volume={13},
  number={},
  pages={59531-59543},
  abstract={Alzheimer’s Disease (AD) poses a major challenge for healthcare systems worldwide, as timely and accurate diagnosis is crucial for patient management and outcome improvement. While experienced medical professionals can often identify AD through conventional assessment methods, limited resources and growing patient populations make large-scale and rapid screening increasingly necessary. In this work, we explore whether the FixMatch algorithm—a semi-supervised learning approach—can aid in classifying Alzheimer’s Disease (AD), Mild Cognitive Impairment (MCI), and Cognitively Normal (CN) by using the ADNI fMRI dataset of 5,182 images. This approach supplements rather than replaces clinical expertise, offering a faster, more standardized classification process where expert labeling is limited. We first assessed various supervised models and determined that VGG19-FFT provided the strongest balance of classification accuracy and computational efficiency. Integrating VGG19-FFT into FixMatch as the teacher model, initial tests using 10% labeled and 90% unlabeled data yielded modest results. A more systematic examination of different labeled-to-unlabeled data splits revealed that a 60:40 ratio enabled FixMatch to achieve classification accuracies of 100% for AD, 99% for CN, and 99% for MCI—on par with fully supervised training. This outcome highlights the potential of FixMatch to significantly reduce labeling requirements, a particular advantage in resource-constrained settings where expert annotations are costly. By striking an effective balance between labeling effort and model performance, the identified 60:40 ratio helps make advanced diagnostic methods both feasible and practical in real-world clinical applications.},
  keywords={Accuracy;Alzheimer's disease;Brain modeling;Data models;Semisupervised learning;Feature extraction;Supervised learning;Training;Overfitting;Labeling;Alzheimer’s diseases;computer vision;supervised learning;semi-supervised learning;FixMatch;VGG-19},
  doi={10.1109/ACCESS.2025.3556964},
  ISSN={2169-3536},
  month={},}@ARTICLE{10978019,
  author={Deenadayalan, T. and Shantharajah, S. P.},
  journal={IEEE Access}, 
  title={Prognostic Survival Analysis for AD Diagnosis and Progression Using MRI Data: An AI-Based Approach}, 
  year={2025},
  volume={13},
  number={},
  pages={89059-89078},
  abstract={Alzheimer’s Disease is a progressive neuro-degenerative disorder and a leading cause of dementia, marked by cognitive decline, memory loss, and behavioral changes. Despite advancements in medical imaging and Artificial Intelligence (AI), early detection and accurate prognostic modeling remain challenging, particularly in distinguishing overlapping disease stages. This study proposes a novel AI framework combining EfficientNetB0, a state-of-the-art deep learning model, with dual attention mechanisms for robust feature extraction and survival analysis using the Alzheimer’s MRI dataset hosted on the Kaggle platform. The model was trained and evaluated on a balanced dataset of 6,400 MRI images, classified into 4 AD stages: Non-Demented (NoD), very Mild-Demented (vMiD), Mild-Demented (MiD), and Moderate-Demented (MoD). The pre-processing steps, including resizing, normalization, and data augmentation, ensured robustness and generalizability. The framework achieved classification accuracies of 99. 93% (training), 93. 60% (validation) and 93. 59% (testing), with a perfect Concordance Index of 1.0 for survival predictions, demonstrating its ability to accurately rank survival times. By integrating survival analysis with deep learning, the framework addresses limitations in previous work, such as reliance on linear assumptions and limited classification capabilities, and provides actionable insights for clinical workflows, supporting personalized treatment and early intervention strategies. Future work will focus on integrating longitudinal data, exploring time-dependent co-variates, and enhancing explainability to promote adoption in diverse clinical settings. This approach represents a significant advancement in AI-driven diagnosis and progression modeling of AD, with the potential to transform patient care and outcomes.},
  keywords={Magnetic resonance imaging;Accuracy;Artificial intelligence;Neuroimaging;Predictive models;Data models;Analytical models;Brain modeling;Genetics;Feature extraction;AD diagnosis;DL classification;survival analysis;MRI processing;CPH model;prognostic modeling},
  doi={10.1109/ACCESS.2025.3564611},
  ISSN={2169-3536},
  month={},}@ARTICLE{10474114,
  author={Luz, Saturnino and Haider, Fasih and Fromm, Davida and Lazarou, Ioulietta and Kompatsiaris, Ioannis and MacWhinney, Brian},
  journal={IEEE Open Journal of Signal Processing}, 
  title={An Overview of the ADReSS-M Signal Processing Grand Challenge on Multilingual Alzheimer's Dementia Recognition Through Spontaneous Speech}, 
  year={2024},
  volume={5},
  number={},
  pages={738-749},
  abstract={The ADReSS-M Signal Processing Grand Challenge was held at the 2023 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2023. The challenge targeted difficult automatic prediction problems of great societal and medical relevance, namely, the detection of Alzheimer's Dementia (AD) and the estimation of cognitive test scoress. Participants were invited to create models for the assessment of cognitive function based on spontaneous speech data. Most of these models employed signal processing and machine learning methods. The ADReSS-M challenge was designed to assess the extent to which predictive models built based on speech in one language generalise to another language. The language data compiled and made available for ADReSS-M comprised English, for model training, and Greek, for model testing and validation. To the best of our knowledge no previous shared research task investigated acoustic features of the speech signal or linguistic characteristics in the context of multilingual AD detection. This paper describes the context of the ADReSS-M challenge, its data sets, its predictive tasks, the evaluation methodology we employed, our baseline models and results, and the top five submissions. The paper concludes with a summary discussion of the ADReSS-M results, and our critical assessment of the future outlook in this field.},
  keywords={Feature extraction;Task analysis;Data models;Signal processing;Biomarkers;Biological system modeling;Acoustics;Biomedical signal processing;medical conditions;Alzheimer's disease;human disease biomarkers;speech processing;natural language processing;multilingual Alzheimer's dementia detection},
  doi={10.1109/OJSP.2024.3378595},
  ISSN={2644-1322},
  month={},}@ARTICLE{10466570,
  author={Woodbright, Mitchell D. and Morshed, Ahsan and Browne, Matthew and Ray, Biplob and Moore, Steven},
  journal={IEEE Access}, 
  title={Toward Transparent AI for Neurological Disorders: A Feature Extraction and Relevance Analysis Framework}, 
  year={2024},
  volume={12},
  number={},
  pages={37731-37743},
  abstract={The lack of interpretability and transparency in deep learning architectures has raised concerns among professionals in various industries and academia. One of the main concerns is the ability to trust these architectures’ without being provided any insight into the decision-making process. Despite these concerns, researchers continue to explore new models and architectures that do not incorporate explainability into their main construct. In the medical industry, it is crucial to provide explanations of any decision, as patient health outcomes can vary according to decisions made. Furthermore, in medical research, incorrectly diagnosed neurological conditions are a high-cost error that contributes significantly to morbidity and mortality. Therefore, the development of new transparent techniques for neurological conditions is critical. This paper presents a novel Autonomous Relevance Technique for an Explainable neurological disease prediction framework called ART-Explain. The proposed technique autonomously extracts features from within the deep learning architecture to create novel visual explanations of the resulting prediction. ART-Explain is an end-to-end autonomous explainable technique designed to present an intuitive and holistic overview of a prediction made by a deep learning classifier. To evaluate the effectiveness of our approach, we benchmark it with other state-of-the-art techniques using three data sets of neurological disorders. The results demonstrate the generalisation capabilities of our technique and its suitability for real-world applications. By providing transparent insights into the decision-making process, ART-Explain can improve end-user trust and enable a better understanding of classification outcomes in the detection of neurological diseases.},
  keywords={Feature extraction;Convolutional neural networks;Neurological diseases;Medical diagnostic imaging;Neurons;Alzheimer's disease;Brain cancer;Tumors;Epilepsy;Artificial intelligence;Explainable AI;Alzheimer’s disease;brain tumor;deep learning;epilepsy;explainable artificial intelligence;feature extraction},
  doi={10.1109/ACCESS.2024.3375877},
  ISSN={2169-3536},
  month={},}@ARTICLE{10969769,
  author={Zheng, Guojiang and Lu, Yang and Chen, Hui},
  journal={IEEE Access}, 
  title={Deep Learning-Based Framework for Predicting Mild Cognitive Impairment Progression in Neurology Using Longitudinal MRI}, 
  year={2025},
  volume={13},
  number={},
  pages={68903-68919},
  abstract={Alzheimer’s disease (AD), a leading neurodegenerative disorder, progresses from an intermediary stage known as Mild Cognitive Impairment (MCI), characterized by measurable cognitive decline with retained functional independence. Accurate prediction of MCI progression to AD is critical for timely interventions. Existing deep learning-based methods for structural MRI (sMRI) analysis predominantly utilize either Convolutional Neural Networks (CNNs), which effectively capture local features but neglect global context, or Transformer architectures that model global dependencies yet require extensive data and computational resources. Additionally, many methods inadequately leverage longitudinal imaging data, limiting their sensitivity to subtle temporal changes in brain morphology. To overcome these limitations, we introduce EffiSwin-MCI, a novel hybrid deep learning framework integrating EfficientNet and Swin Transformer architectures, specifically designed for longitudinal sMRI analysis. The primary novelty of EffiSwin-MCI lies in its sliding-window attention mechanism, inspired by the Swin Transformer, which effectively integrates localized spatial dependencies within 2D sMRI slices, combined with temporal attention blocks that fuse spatial-temporal features across longitudinal scans at two distinct time points (T1 and T2). EfficientNet-B2 serves as a computationally efficient backbone, extracting hierarchical spatial features crucial for detailed morphological characterization. This alternating spatial and temporal attention strategy uniquely captures progressive local and global structural changes indicative of cognitive decline. Comprehensive experiments conducted on the Alzheimer’s Disease ADNI dataset demonstrate the proposed model’s superior performance compared to state-of-the-art CNN and Transformer-based approaches, achieving an accuracy of 81.69%, recall of 80.27%, precision of 84.35%, and F1-score of 82.27%. EffiSwin-MCI’s interpretability is further validated through Grad-CAM visualizations, highlighting critical neurodegenerative biomarkers such as the hippocampus and amygdala, reinforcing its clinical relevance for early prediction and intervention strategies in MCI management.},
  keywords={Transformers;Brain modeling;Feature extraction;Computer architecture;Magnetic resonance imaging;Accuracy;Computational modeling;Alzheimer's disease;Adaptation models;Context modeling;Vision transformer;deep learning;Alzheimer’s disease;disease progression;brain MRI},
  doi={10.1109/ACCESS.2025.3562432},
  ISSN={2169-3536},
  month={},}@ARTICLE{9380278,
  author={Basheer, Shakila and Bhatia, Surbhi and Sakri, Sapiah Binti},
  journal={IEEE Access}, 
  title={Computational Modeling of Dementia Prediction Using Deep Neural Network: Analysis on OASIS Dataset}, 
  year={2021},
  volume={9},
  number={},
  pages={42449-42462},
  abstract={Alzheimer is a progressive disease and it is the most prevalent neurodegenerative disorder. It is believed that the people with mild cognitive impairment are at high risk of developing this disease. According to the annual report released by the Alzheimer's Association®2020, Alzheimer is the sixth leading cause of death in the United States. Thus, there is a need of educating people about this disease, reducing the risks by militating the necessary precautions to disseminate its affect by diagnosing it at early stages. It is also important to propose some recent advancement in this research which can help in early prediction of the disease using machine learning techniques. This paper intends to develop the novel algorithm by proposing changes in the designing of capsule network for best prediction results and making the model computationally efficient. The research is conducted on the Open Access Series of Imaging Studies (OASIS) dataset with dimensions (373 X 15) to diagnose the labels into two groups, as demented and non-demented. The novelty lies in conducting the in-depth research in identifying the importance of features, correlation study between factors and density of data showing status of factors by studying hierarchical examination of all the data points available using exploratory data analysis. Several optimization functions are conducted on the variables and feature selection is done to make the model faster and more accurate. The claims have been validated by showing the correlation accuracy at several iterations and layers with an admissible accuracy of 92.39%. The model is compared with state-of-art deep learning classifiers taken as benchmarks using different performance metrics. The ablation study is conducted on the proposed model using OASIS dataset to justify the predictions of the model.},
  keywords={Feature extraction;Deep learning;Magnetic resonance imaging;Machine learning;Predictive models;Neuroimaging;Prediction algorithms;Dementia;Alzheimer’s disease;neural network models;machine learning;deep learning;convolutional neural networks;capsule networks},
  doi={10.1109/ACCESS.2021.3066213},
  ISSN={2169-3536},
  month={},}@ARTICLE{9926057,
  author={Kujur, Anima and Raza, Zahid and Khan, Arfat Ahmad and Wechtaisong, Chitapong},
  journal={IEEE Access}, 
  title={Data Complexity Based Evaluation of the Model Dependence of Brain MRI Images for Classification of Brain Tumor and Alzheimer’s Disease}, 
  year={2022},
  volume={10},
  number={},
  pages={112117-112133},
  abstract={The convolutional neural networks (CNN) have shown promising results for various classification problems over the past years. However, selecting various CNN architectures is still challenging as each architecture performs differently with the same dataset. This research aims to evaluate the dependence of brain MRI on various predictive models of CNN based on the complexity of the data for Brain Tumor and Alzheimer’s Disease. Our proposed approach has three parts. First part is the pre-processing of the data which mainly focuses on class balancing and the estimation of data complexity. The second part uses stratified k-fold cross-validation for more reliable results. The last part corresponds to the implementation of four CNN models applying described methods. This paper compares the classification performance of rigorous experimentation on four CNN variants namely S-CNN (CNN trained from scratch), ResNet50, InceptionV3, and Xception over two brain MRI image datasets evaluated with and without the use of Principal Component Analysis (PCA). The work benchmarks CNN models by comparing the average scores of Accuracy, Precision, Recall, F1 score, and AUC score from the stratified five-fold cross-validation.},
  keywords={Tumors;Diseases;Magnetic resonance imaging;Alzheimer's disease;Brain modeling;Complexity theory;Data models;Convolutional neural networks;Principle component analysis;Magnetic imaging resonance (MRI);brain tumor;alzheimer’s disease;S-CNN;ResNet50;inceptionV3;Xception;stratified k-fold;principal component analysis (PCA)},
  doi={10.1109/ACCESS.2022.3216393},
  ISSN={2169-3536},
  month={},}@ARTICLE{11112673,
  author={Du, Tianyu and Ma, Kai and Yang, Xibei and Zhang, Daoqiang},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Hyper-Ordinal Pattern: Measuring High-Order Connection Relationship in Brain Disease Networks}, 
  year={2025},
  volume={33},
  number={},
  pages={3040-3052},
  abstract={Brain hyper-networks as a kind of hypergraph for brain network analysis, describing the high-order interactions among brain regions, have been extensively utilized in research on brain diseases such as mild cognitive impairment (MCI) and Alzheimer’s disease (AD). Recently, several hypergraph representation methods (e.g., hypergraph neural network) have been constructed for investigating brain hyper-networks. However, most of the existing methods neglected the connection relationships on hyperedges with important weighted information in brain hyper-networks. To tackle this problem, we propose hyper-ordinal pattern (HOP) as a novel approach for representing and analyzing brain hyper-networks. Different from the existing hypergraph representation studies, we utilize the ordinal pattern relationships on hyperedges with weighted information to construct HOPs for brain hyper-networks. In HOP, each node is concatenated via ordinal hyperedges, where hyperedge weights have ordinal pattern relationships (e.g., descending order). We construct HOP for each node in brain hyper-networks and propose node HOP (NHOP) kernel for measuring node similarity in brain hyper-networks. Based on NHOP kernel, we further present a new brain hyper-network kernel called ordinal pattern based hyper-network (OPHN) kernel to calculate the brain hyper-network similarity. In order to assess the performance of the proposed OPHN kernel, we conduct the extensive experiments in brain hyper-networks of brain diseases including MCI and AD. The experimental results demonstrate that the proposed OPHN kernel is better than the state-of-the-art competing methods (e.g., hyper-graph neural network) in the classification tasks of brain diseases. Additionally, the proposed NHOP kernel can effectively identify altered hyper-ordinal patterns in the brain hyper-networks of patients with brain diseases.},
  keywords={Diseases;Kernel;Correlation;Functional magnetic resonance imaging;Brain modeling;Alzheimer's disease;Statistical analysis;Graph neural networks;Optical fiber networks;Network analyzers;Brain hyper-network;ordinal pattern;fMRI;brain disease;classification},
  doi={10.1109/TNSRE.2025.3595655},
  ISSN={1558-0210},
  month={},}@ARTICLE{10242080,
  author={Nguyen, Huy Hoang and Blaschko, Matthew B. and Saarakkala, Simo and Tiulpin, Aleksei},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Clinically-Inspired Multi-Agent Transformers for Disease Trajectory Forecasting From Multimodal Data}, 
  year={2024},
  volume={43},
  number={1},
  pages={529-541},
  abstract={Deep neural networks are often applied to medical images to automate the problem of medical diagnosis. However, a more clinically relevant question that practitioners usually face is how to predict the future trajectory of a disease. Current methods for prognosis or disease trajectory forecasting often require domain knowledge and are complicated to apply. In this paper, we formulate the prognosis prediction problem as a one-to-many prediction problem. Inspired by a clinical decision-making process with two agents–a radiologist and a general practitioner – we predict prognosis with two transformer-based components that share information with each other. The first transformer in this framework aims to analyze the imaging data, and the second one leverages its internal states as inputs, also fusing them with auxiliary clinical data. The temporal nature of the problem is modeled within the transformer states, allowing us to treat the forecasting problem as a multi-task classification, for which we propose a novel loss. We show the effectiveness of our approach in predicting the development of structural knee osteoarthritis changes and forecasting Alzheimer’s disease clinical status directly from raw multi-modal data. The proposed method outperforms multiple state-of-the-art baselines with respect to performance and calibration, both of which are needed for real-world applications. An open-source implementation of our method is made publicly available at https://github.com/Oulu-IMEDS/CLIMATv2.},
  keywords={Transformers;Diseases;Prognostics and health management;Imaging;Task analysis;Medical services;Trajectory;Deep Learning;knee;osteoarthritis;prognosis prediction},
  doi={10.1109/TMI.2023.3312524},
  ISSN={1558-254X},
  month={Jan},}@ARTICLE{9661371,
  author={Ahmed, Samsuddin and Lee, Kun Ho and Jung, Ho Yub},
  journal={IEEE Access}, 
  title={Robust Hippocampus Localization From Structured Magnetic Resonance Imaging Using Similarity Metric Learning}, 
  year={2022},
  volume={10},
  number={},
  pages={7141-7152},
  abstract={Accurate demarcation of anatomical landmarks in 3D medical imaging is a safety-critical and challenging task. State-of-the-art approaches formulate landmark localization either as a classification or as a regression problem. In this study, feature classification is performed as a verification step in a cascaded Hough regression networks (HRNs) for hippocampus localization in the structured magnetic resonance images of the brain. Global and local features of the landmarks are learned with coarse prediction and fine-tuning convolutional neural networks for coarse-to-fine localization. Siamese network was trained to learn a deep metric for verifying the roughly estimated locations. Feature verification with the Siamese network drops the outlier predictions and increase the robustness in prediction. Three-view patches(TVPs) with a size of  $64\times 64\times 3$  are fed for rough estimation while the TVP sizes for Siamese-based verification and Hough regression network (HRN)-based fine-grained estimations are  $32\times 32\times 3$  and  $16\times 16\times 3$ , respectively. The experiment was performed on the Gwangju Alzheimer’s and Related Dementia’s (GARD) cohort data set. The proposed approach demonstrated better performance with the errors of 1.70±0.50 millimeters(mm) and 1.66±0.49 mm for localizing the left and right hippocampi in the GARD data set. In Alzheimer’s Disease Neuroimaging Initiative (ADNI) data set, the observed errors were 1.79 ± 0.83 mm and 1.55 ± 0.61 mm for localizing left and right hippocampus, respectively. Our results are comparable to those obtained by the state-of-the-art methods.},
  keywords={Hippocampus;Location awareness;Magnetic resonance imaging;Alzheimer's disease;Diseases;Predictive models;Estimation;Landmark-localization;hippocampus;Hough CNN;Siamese network},
  doi={10.1109/ACCESS.2021.3137824},
  ISSN={2169-3536},
  month={},}@ARTICLE{9203784,
  author={Li, Jialiang and Yao, Zhaomin and Duan, Meiyu and Liu, Shuai and Li, Fei and Zhu, Haiyang and Xia, Zhiqiang and Huang, Lan and Zhou, Fengfeng},
  journal={IEEE Access}, 
  title={MuscNet, a Weighted Voting Model of Multi-Source Connectivity Networks to Predict Mild Cognitive Impairment Using Resting-State Functional MRI}, 
  year={2020},
  volume={8},
  number={},
  pages={174023-174031},
  abstract={The neurological disorder mild cognitive impairment (MCI) demonstrates minor impacts on the patient’s daily activities and may be ignored as the status of normal aging. But some of the MCI patients may further develop into severe statuses like Alzheimer’s disease (AD). The brain functional connectivity network (BFCN) was usually constructed from the resting-state functional magnetic resonance imaging (rs-fMRI) data. This technology has been widely used to detect the neurodegenerative dementia and to reveal the intrinsic mechanism of neural activities. The BFCN edge was usually determined by the pairwise correlation between the brain regions. This study proposed a weighted voting model of multi-source connectivity networks (MuscNet) by integrating multiple BFCNs of different correlation coefficients. Our model was further improved by removing redundant features. The experimental data demonstrated that different BFCNs contributed complementary information to each other and MuscNet outperformed the existing models on detecting MCI patients. The previous study suggested the existence of multiple solutions with similarly good performance for a machine learning problem. The proposed model MuscNet utilized a weighted voting strategy to slightly outperform the existing studies, suggesting an effective way to fuse multiple base models. The reason may need further theoretical investigations about why different base models contribute to each other for the MCI prediction.},
  keywords={Correlation;Correlation coefficient;Brain modeling;Measurement;Dementia;Time series analysis;Mild cognitive impairment;Alzheimer’s disease;resting-state functional MRI;brain functional connectivity network;multi-source connectivity network;weighted voting model;MuscNet},
  doi={10.1109/ACCESS.2020.3025828},
  ISSN={2169-3536},
  month={},}@ARTICLE{10772038,
  author={Theodoropoulos, Christos and Catalin Coman, Andrei and Henderson, James and Moens, Marie-Francine},
  journal={IEEE Access}, 
  title={Enhancing Biomedical Knowledge Discovery for Diseases: An Open-Source Framework Applied on Rett Syndrome and Alzheimer’s Disease}, 
  year={2024},
  volume={12},
  number={},
  pages={180652-180673},
  abstract={The rapidly increasing number of biomedical publications presents a significant challenge for efficient knowledge discovery. To address this, we introduce an open-source, end-to-end framework designed to automatically extract and construct knowledge about specific diseases directly from unstructured text. To facilitate research in disease-related knowledge discovery, we create two annotated datasets focused on Rett syndrome (RS) and Alzheimer’s disease (AD), enabling the identification of semantic relations between various biomedical entities. We perform extensive benchmarking to evaluate different approaches for representing relations and entities, providing insights into optimal modeling strategies for semantic relation detection and highlighting language models’ competence in knowledge discovery. To gain a deeper understanding of the internal mechanisms of transformer models, we also conduct probing experiments, analyzing different layer representations and attention scores, to explore transformers’ ability to capture semantic relations within the text. Both the code and the datasets will be publicly available at https://github.com/christos42/Enhancing-Biomedical-Knowledge-Discovery-for-Diseases, encouraging further research in biomedical knowledge discovery.},
  keywords={Diseases;Semantics;Knowledge discovery;Proteins;Protein engineering;Annotations;Alzheimer's disease;Pipelines;Biological system modeling;Peptides;Benchmarking;corpus creation;evaluation;knowledge discovery;language model probing;language resources;NLP datasets;relation detection},
  doi={10.1109/ACCESS.2024.3509714},
  ISSN={2169-3536},
  month={},}@ARTICLE{10462208,
  author={Adebisi, Abdulyekeen T. and Lee, Ho-Won and Veluvolu, Kalyana C.},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={EEG-Based Brain Functional Network Analysis for Differential Identification of Dementia-Related Disorders and Their Onset}, 
  year={2024},
  volume={32},
  number={},
  pages={1198-1209},
  abstract={Diagnosing and treating dementia, including mild cognitive impairment (MCI), is challenging due to diverse disease types and overlapping symptoms. Early MCI detection is vital as it can precede dementia, yet distinguishing it from later stage dementia is intricate due to subtle symptoms. The primary objective of this study is to adopt a complex network perspective to unravel the underlying pathophysiological mechanisms of dementia-related disorders. Leveraging the extensive availability of electroencephalogram (EEG) data, our study focuses on the meticulous identification and analysis of EEG-based brain functional network (BFNs) associated with dementia-related disorders. To achieve this, we employ the Phase Lag Index (PLI) as a connectivity measure, offering a comprehensive view of neural interactions. To enhance the analytical rigor, we introduce a data-driven threshold selection technique. This innovative approach allows us to compare the topological structures of the formulated BFNs using complex network measures quantitatively and statistically. Furthermore, we harness the power of these BFNs by utilizing them as pre-defined graph inputs for a Graph Convolution Network (GCN-net) based approach. The results demonstrate that graph theory metrics, such as the rich-club coefficient, transitivity, and assortativity coefficients, effectively distinguish between MCI, Alzheimer’s disease (AD) and vascular dementia (VD). Furthermore, GCN-net achieves high accuracy (95.07% delta, 80.62% theta) and F1-scores (0.92 delta, 0.67 theta), highlighting the effectiveness of EEG-based BFNs in the analysis of dementia-related disorders.},
  keywords={Electroencephalography;Electrodes;Diseases;Indexes;Complex networks;Network analyzers;Convolution;Alzheimer’s disease (AD);complex network theory;deep learning;electroencephalogram (EEG);graph theory;graph convolution networks (GCN);functional connectivity},
  doi={10.1109/TNSRE.2024.3374651},
  ISSN={1558-0210},
  month={},}@ARTICLE{10735133,
  author={Jiang, Yishan and Yang, Hyung-Jeong and Kim, Jahae and Tang, Zhenzhou and Ruan, Xiukai},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Power of Multi-Modality Variables in Predicting Parkinson's Disease Progression}, 
  year={2025},
  volume={29},
  number={2},
  pages={1343-1356},
  abstract={Parkinson's disease (PD) is one of the most common neurodegenerative disorders. The increasing demand for high-accuracy forecasts of disease progression has led to a surge in research employing multi-modality variables for prediction. In this review, we selected articles published from 2016 through June 2024, adhering strictly to our exclusion-inclusion criteria. These articles employed a minimum of two types of variables, including clinical, genetic, biomarker, and neuroimaging modalities. We conducted a comprehensive review and discussion on the application of multi-modality approaches in predicting PD progression. The predictive mechanisms, advantages, and shortcomings of relevant key modalities in predicting PD progression are discussed in the paper. The findings suggest that integrating multiple modalities resulted in more accurate predictions compared to those of fewer modalities in similar conditions. Furthermore, we identified some limitations in the existing field. Future studies that harness advancements in multi-modality variables and machine learning algorithms can mitigate these limitations and enhance predictive accuracy in PD progression.},
  keywords={Diseases;Genetics;Neuroimaging;Biomedical imaging;Bioinformatics;Forecasting;Databases;Predictive models;Parkinson's disease;Deep learning;Machine learning;Parkinson's disease;progression prediction;multi-modality;machine / deep learning},
  doi={10.1109/JBHI.2024.3482180},
  ISSN={2168-2208},
  month={Feb},}@ARTICLE{8886705,
  author={Shen, Li and Thompson, Paul M.},
  journal={Proceedings of the IEEE}, 
  title={Brain Imaging Genomics: Integrated Analysis and Machine Learning}, 
  year={2020},
  volume={108},
  number={1},
  pages={125-162},
  abstract={Brain imaging genomics is an emerging data science field, where integrated analysis of brain imaging and genomics data, often combined with other biomarker, clinical, and environmental data, is performed to gain new insights into the phenotypic, genetic, and molecular characteristics of the brain as well as their impact on normal and disordered brain function and behavior. It has enormous potential to contribute significantly to biomedical discoveries in brain science. Given the increasingly important role of statistical and machine learning in biomedicine and rapidly growing literature in brain imaging genomics, we provide an up-to-date and comprehensive review of statistical and machine learning methods for brain imaging genomics, as well as a practical discussion on method selection for various biomedical applications.},
  keywords={Genomics;Bioinformatics;Brain modeling;Machine learning;Biomedical imaging;Big data;brain imaging;genomics;machine learning;statistics},
  doi={10.1109/JPROC.2019.2947272},
  ISSN={1558-2256},
  month={Jan},}@ARTICLE{11106739,
  author={Hassan, Najmul and Miah, Abu Saleh Musa and Okuyama, Yuichi and Shin, Jungpil},
  journal={IEEE Open Journal of the Computer Society}, 
  title={Neurological Disorder Recognition via Comprehensive Feature Fusion by Integrating Deep Learning and Texture Analysis}, 
  year={2025},
  volume={6},
  number={},
  pages={1366-1377},
  abstract={Neurological disorders, including Brain Tumors (BTs), Alzheimer’s Disease (AD), and Parkinson’s Disease (PD), pose significant global health challenges. Early and accurate diagnosis is crucial for effective treatment and improved patient outcomes. Magnetic Resonance Imaging (MRI) is a key diagnostic tool, but traditional Machine Learning (ML) approaches often rely on labor-intensive handcrafted features, leading to inconsistent performance. Recent advancements in Deep Learning (DL) enable automated feature extraction, which offers improved robustness and scalability. However, many existing methods face challenges in fully exploiting the complementary strengths of DL and handcrafted features across multiple disease types. This study proposes a novel hybrid DL model that integrates automated deep features with statistical textural descriptors for the classification of BTs, AD, and PD. The model employs a dual-stream architecture: (1) a modified VGG16 convolutional neural network (CNN), chosen for its favorable trade-off between performance and computational efficiency in medical imaging, to extract deep features from MRI slices, and (2) a sequential one dimensional (1D) CNN to process six gray-level co-occurrenc matrix (GLCM)derived handcrafted features, empirically validated for their superior discriminative power in neuroanatomical texture analysis. By integrating these complementary feature sets, the model leverages global patterns and fine-grained textural details, resulting in a robust and comprehensive representation for accurate and reliable medical image classification. Gradient-weighted class activation mapping (Grad-CAM) is incorporated to enhance interpretability by localizing diagnostically relevant brain regions. The fused features are passed through a fully connected layer for final classification. The proposed model was evaluated on four publicly available MRI datasets, achieving accuracies of 98.86%, 99.50%, 98.52%, and 99.13% on the CE-MRI (multi-class BT), Br35H (binary BT), AD, and PD datasets, respectively. The model achieved an average classification accuracy of 99.05% across the three neurological disorders. Our method outperforms recent state-of-the-art (SOTA) methods, which shows the effectiveness of the proposed model integrating DL and handcrafted features to develop interpretable, robust, and generalizable AI-driven diagnostic systems.},
  keywords={Feature extraction;Magnetic resonance imaging;Accuracy;Diseases;Neurological diseases;Brain modeling;Brain tumors;Convolutional neural networks;Solid modeling;Semantics;Alzheimer’s disease;parkinson’s disease;brain tumor;dual stream deep learning;neurological disorder disease;gray-level co-occurrence matrices;MRI},
  doi={10.1109/OJCS.2025.3594701},
  ISSN={2644-1268},
  month={},}@ARTICLE{10909332,
  author={Del Pup, Federico and Zanola, Andrea and Fabrice Tshimanga, Louis and Bertoldo, Alessandra and Atzori, Manfredo},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={The More, the Better? Evaluating the Role of EEG Preprocessing for Deep Learning Applications}, 
  year={2025},
  volume={33},
  number={},
  pages={1061-1070},
  abstract={The last decade has witnessed a notable surge in deep learning applications for electroencephalography (EEG) data analysis, showing promising improvements over conventional statistical techniques. However, deep learning models can underperform if trained with bad processed data. Preprocessing is crucial for EEG data analysis, yet there is no consensus on the optimal strategies in deep learning scenarios, leading to uncertainty about the extent of preprocessing required for optimal results. This study is the first to thoroughly investigate the effects of EEG preprocessing in deep learning applications, drafting guidelines for future research. It evaluates the effects of varying preprocessing levels, from raw and minimally filtered data to complex pipelines with automated artifact removal algorithms. Six classification tasks (eye blinking, motor imagery, Parkinson’s, Alzheimer’s disease, sleep deprivation, and first episode psychosis) and four established EEG architectures were considered for the evaluation. The analysis of 4800 trained models revealed statistical differences between preprocessing pipelines at the intra-task level for each model and at the inter-task level for the largest model. Models trained on raw data consistently performed poorly, always ranking last in average scores. In addition, models seem to benefit more from minimal pipelines without artifact handling methods. These findings suggest that EEG artifacts may affect the performance and generalizability of deep neural networks.},
  keywords={Electroencephalography;Brain modeling;Recording;Sleep;Pipelines;Deep learning;Alzheimer's disease;Data models;Data preprocessing;Filtering;EEG;preprocessing;deep learning;motor imagery;disease classification},
  doi={10.1109/TNSRE.2025.3547616},
  ISSN={1558-0210},
  month={},}@ARTICLE{10890994,
  author={Shaheen, Hina and Melnik, Roderick},
  journal={IEEE Access}, 
  title={Brain Network Dynamics and Multiscale Modeling of Neurodegenerative Disorders: A Review}, 
  year={2025},
  volume={13},
  number={},
  pages={33074-33100},
  abstract={It is essential to understand the complex structure of the human brain to develop new treatment approaches for neurodegenerative disorders (NDDs). This review paper comprehensively discusses the challenges associated with modelling the complex brain networks and dynamic processes involved in NDDs, particularly Alzheimer’s disease (AD), Parkinson’s disease (PD), and cortical spreading depression (CSD). We investigate how the brain’s biological processes and associated multiphysics interact and how this influences the structure and functionality of the brain. We review the literature on brain network models and dynamic processes, highlighting the need for sophisticated mathematical and statistical modelling techniques. Specifically, we go through large-scale brain network models relevant to AD and PD, highlighting the pathological mechanisms and potential therapeutic strategies investigated in the literature. Additionally, we investigate the propagation of CSD in the brain and its implications for neurological disorders. Furthermore, we discuss how data-driven approaches and artificial neural networks refine and validate models related to NDDs. Overall, this review underscores the significance of coupled multiscale models in deciphering disease mechanisms, offering potential avenues for therapeutic development and advancing our understanding of pathological brain dynamics.},
  keywords={Brain modeling;Biological system modeling;Diseases;Organizations;Mathematical models;Neurons;Reviews;Data models;Brain;Analytical models;Neurodegenerative diseases;brain networks;dynamic processes;multiphysics modelling;biochemical activities;pathological mechanisms;therapeutic strategies;mathematical modelling;statistical analysis and Bayesian inference techniques;large-scale brain network models;data-driven approaches;validation;inverse problems;AI tools;systems neurosciences},
  doi={10.1109/ACCESS.2025.3542634},
  ISSN={2169-3536},
  month={},}@ARTICLE{9222094,
  author={Torres-Velázquez, Maribel and Chen, Wei-Jie and Li, Xue and McMillan, Alan B.},
  journal={IEEE Transactions on Radiation and Plasma Medical Sciences}, 
  title={Application and Construction of Deep Learning Networks in Medical Imaging}, 
  year={2021},
  volume={5},
  number={2},
  pages={137-159},
  abstract={Deep learning (DL) approaches are part of the machine learning (ML) subfield concerned with the development of computational models to train artificial intelligence systems. DL models are characterized by automatically extracting high-level features from the input data to learn the relationship between matching datasets. Thus, its implementation offers an advantage over common ML methods that often require the practitioner to have some domain knowledge of the input data to select the best latent representation. As a result of this advantage, DL has been successfully applied within the medical imaging field to address problems, such as disease classification and tumor segmentation for which it is difficult or impossible to determine which image features are relevant. Therefore, taking into consideration the positive impact of DL on the medical imaging field, this article reviews the key concepts associated with its evolution and implementation. The sections of this review summarize the milestones related to the development of the DL field, followed by a description of the elements of deep neural network and an overview of its application within the medical imaging field. Subsequently, the key steps necessary to implement a supervised DL application are defined, and associated limitations are discussed.},
  keywords={Biological neural networks;Neurons;Biomedical imaging;Training;Artificial intelligence;Data models;Feature extraction;Classification;convolutional neural networks (CNNs);deep learning (DL);medical imaging;segmentation;synthesis},
  doi={10.1109/TRPMS.2020.3030611},
  ISSN={2469-7303},
  month={March},}@ARTICLE{10993430,
  author={Zhang, Jingyi and Zhao, Shishun and Xu, Yang and Hu, Tao},
  journal={IEEE Access}, 
  title={ICBoost: An XGBoost-Based Unbiased Transformed Algorithm for Survival Regression}, 
  year={2025},
  volume={13},
  number={},
  pages={82807-82820},
  abstract={Prediction models for disease onset are critical in biomedical research and survival analysis. With machine learning methods increasingly being used to handle survival data with censoring, unbiased transformation theory offers an alternative method for estimating survival tasks in the presence of such censoring, thereby enhancing model accuracy. This study aims to develop a reliable and efficient prediction algorithm that utilizes unbiased transformation to improve machine learning model performance on interval-censored data. Therefore, we present ICBoost, a novel survival algorithm that integrates regression trees and ensemble methods specifically designed for interval-censored data. Unlike right-censored data, where the exact event time is unknown but occurs after a known time point, interval-censored data only provides intervals within which the event occurred. The inherent complexity of interval-censored data poses challenges for accurate survival prediction. To overcome these challenges, we propose a kernel density estimation-based unbiased transformation approach to estimate failure time. Furthermore, we develop a novel ensemble framework that combines XGBoost with censoring unbiased transformation. This framework allows for investigating the relationships between patient survival and covariates, thereby enhancing prediction accuracy and model interpretability. We evaluated the performance of the ICBoost algorithm against existing methods using various real and simulated datasets. Our results showed that ICBoost exhibited superior performance in identifying hidden patterns for survival prediction tasks, particularly in datasets related to Alzheimer’s disease and the emergence of permanent teeth in the medical field. ICBoost outperformed other methods, as evidenced by lower root-mean-square error, mean absolute error, and Brier score values.},
  keywords={Prediction algorithms;Kernel;Machine learning;Data models;Predictive models;Machine learning algorithms;Estimation;Classification algorithms;Hazards;Ensemble learning;Survival data;unbiased transformation;ensemble methods;interval-censored data},
  doi={10.1109/ACCESS.2025.3568196},
  ISSN={2169-3536},
  month={},}@ARTICLE{10283869,
  author={Tong, Li and Shi, Wenqi and Isgut, Monica and Zhong, Yishan and Lais, Peter and Gloster, Logan and Sun, Jimin and Swain, Aniketh and Giuste, Felipe and Wang, May D.},
  journal={IEEE Reviews in Biomedical Engineering}, 
  title={Integrating Multi-Omics Data With EHR for Precision Medicine Using Advanced Artificial Intelligence}, 
  year={2024},
  volume={17},
  number={},
  pages={80-97},
  abstract={With the recent advancement of novel biomedical technologies such as high-throughput sequencing and wearable devices, multi-modal biomedical data ranging from multi-omics molecular data to real-time continuous bio-signals are generated at an unprecedented speed and scale every day. For the first time, these multi-modal biomedical data are able to make precision medicine close to a reality. However, due to data volume and the complexity, making good use of these multi-modal biomedical data requires major effort. Researchers and clinicians are actively developing artificial intelligence (AI) approaches for data-driven knowledge discovery and causal inference using a variety of biomedical data modalities. These AI-based approaches have demonstrated promising results in various biomedical and healthcare applications. In this review paper, we summarize the state-of-the-art AI models for integrating multi-omics data and electronic health records (EHRs) for precision medicine. We discuss the challenges and opportunities in integrating multi-omics data with EHRs and future directions. We hope this review can inspire future research and developing in integrating multi-omics data with EHRs for precision medicine.},
  keywords={Feature extraction;Bioinformatics;Precision medicine;Diseases;Cancer;Dimensionality reduction;Medical services;Multi-omics;electronic health records;data integration;artificial intelligence;precision},
  doi={10.1109/RBME.2023.3324264},
  ISSN={1941-1189},
  month={},}@ARTICLE{10127976,
  author={Zuo, Qiankun and Tian, Hao and Li, Ruiheng and Guo, Jia and Hu, Jianmin and Tang, Long and Di, Yi and Kong, Heng},
  journal={IEEE Access}, 
  title={Hemisphere-Separated Cross-Connectome Aggregating Learning via VAE-GAN for Brain Structural Connectivity Synthesis}, 
  year={2023},
  volume={11},
  number={},
  pages={48493-48505},
  abstract={The brain network is an effective tool and has been widely used in the field of brain neurodegenerative disease analysis. Due to the high cost of accessing medical image data, efforts have been devoted to investigating data augmentation. However, the brain network containing topological characteristics of non-European space is different from the traditional image data, which makes it challenging to synthesize brain structural connectivity and limits the application of brain network analysis. In this paper, a Hemisphere-separated Cross-connectome Aggregating Learning (HCAL) model is proposed to synthesize realistic and diverse brain structural connectivities. Specifically, the latent representation is transformed from structural connectivity by the graph variational autoencoder (GVAE). To generate more diverse and high-quality structural connectivities, the hemisphere-separated generator with a cross-connectome aggregating mechanism is developed to first learn local topological patterns by splitting the whole brain into inter- and intra-hemispheres, then capture global topological characteristics among all the neighbors for each brain region. Also, the connectivity-aware discriminator is devised to make the adversarial training stable and enhance the disease diagnosis. Evaluations of the public Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset show that the proposed model generates brain structural networks with higher quality and more diversity than related methods. In addition, the classification performance using the augmented data achieved by our approach achieves an accuracy improvement of over 3% compared with the competing method. The proposed model provides an alternative way to synthesize brain networks for connectivity-based disease analysis.},
  keywords={Diseases;Brain modeling;Generators;Feature extraction;Convolutional neural networks;Generative adversarial networks;Alzheimer's disease;Information-assisted graph encoder;cross-connectome aggregating mechanism;hemisphere-separated graph generator;connectivity-aware discriminator;brain structural connectivity;graph convolutional network;Alzheimer’s disease},
  doi={10.1109/ACCESS.2023.3276989},
  ISSN={2169-3536},
  month={},}@ARTICLE{11031459,
  author={Zheng, Chuheng and Bouazizi, Mondher and Okunishi, Taichi and Ohtsuki, Tomoaki and Kitazawa, Momoko and Horigome, Toshiro and Kishimoto, Taishiro},
  journal={IEEE Access}, 
  title={Face Mesh for Dementia Detection: Evaluating Data Augmentation in Deep Learning and Traditional Machine Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={104501-104520},
  abstract={Alzheimer’s disease (AD) stands as a prevalent form of dementia, primarily impacting the elderly, and presently lacking any known cure. Early screening and intervention have demonstrated efficacy for both current and prospective treatments. With the global population aging, early detection of AD has become imperative. Language-based approaches for dementia detection have received considerable attention in research due to dementia’s nature of hurting cognitive and language functions. Facial features, on the other hand, have been comparatively neglected despite their potential in identifying AD. The face mesh, comprising 478 landmarks, serves as a rich and informative facial representation. This study concentrates on leveraging face mesh data extracted from the PROMPT dataset for AD detection. The dataset comprises 445 voice and video recordings from 117 dementia patients and healthy individuals collected during professionally conducted interview sessions. We explored data augmentation techniques to address the challenges of over-fitting, particularly impactful in training neural networks on a small dataset. Deep learning methods, including transformer, Convolutional Neural Networks (CNN), and Long Short-Term Memory (LSTM) networks, were employed to classify dementia patients and healthy subjects. By augmenting the dataset, we improved the performance of the deep learning methods. The combined use of 1D CNN networks and data augmentation method reported the highest accuracy of 76%, which is the state-of-the-art accuracy in dementia detection using face mesh. These results confirmed the effectiveness of our data augmentation methods. They also underscore the potential of face-related features in enhancing early detection approaches for AD.},
  keywords={Dementia;Faces;Face recognition;Deep learning;Facial features;Data augmentation;Accuracy;Three-dimensional displays;Aging;Psychology;Dementia detection;face mesh;deep learning;data augmentation},
  doi={10.1109/ACCESS.2025.3579241},
  ISSN={2169-3536},
  month={},}@ARTICLE{9947339,
  author={Bass, Cher and Silva, Mariana da and Sudre, Carole and Williams, Logan Z. J. and Sousa, Helena S. and Tudosiu, Petru-Daniel and Alfaro-Almagro, Fidel and Fitzgibbon, Sean P. and Glasser, Matthew F. and Smith, Stephen M. and Robinson, Emma C},
  journal={IEEE Transactions on Medical Imaging}, 
  title={ICAM-Reg: Interpretable Classification and Regression With Feature Attribution for Mapping Neurological Phenotypes in Individual Scans}, 
  year={2023},
  volume={42},
  number={4},
  pages={959-970},
  abstract={An important goal of medical imaging is to be able to precisely detect patterns of disease specific to individual scans; however, this is challenged in brain imaging by the degree of heterogeneity of shape and appearance. Traditional methods, based on image registration, historically fail to detect variable features of disease, as they utilise population-based analyses, suited primarily to studying group-average effects. In this paper we therefore take advantage of recent developments in generative deep learning to develop a method for simultaneous classification, or regression, and feature attribution (FA). Specifically, we explore the use of a VAE-GAN (variational autoencoder - general adversarial network) for translation called ICAM, to explicitly disentangle class relevant features, from background confounds, for improved interpretability and regression of neurological phenotypes. We validate our method on the tasks of Mini-Mental State Examination (MMSE) cognitive test score prediction for the Alzheimer’s Disease Neuroimaging Initiative (ADNI) cohort, as well as brain age prediction, for both neurodevelopment and neurodegeneration, using the developing Human Connectome Project (dHCP) and UK Biobank datasets. We show that the generated FA maps can be used to explain outlier predictions and demonstrate that the inclusion of a regression module improves the disentanglement of the latent space. Our code is freely available on GitHub https://github.com/CherBass/ICAM.},
  keywords={Diseases;Feature extraction;Biomedical imaging;Alzheimer's disease;Imaging;Training;Neuroimaging;Brain imaging;deep generative models;feature attribution;image-to-image translation},
  doi={10.1109/TMI.2022.3221890},
  ISSN={1558-254X},
  month={April},}@ARTICLE{9839492,
  author={Akintoye, Samson B. and Han, Liangxiu and Zhang, Xin and Chen, Haoming and Zhang, Daoqiang},
  journal={IEEE Access}, 
  title={A Hybrid Parallelization Approach for Distributed and Scalable Deep Learning}, 
  year={2022},
  volume={10},
  number={},
  pages={77950-77961},
  abstract={Recently, Deep Neural Networks (DNNs) have recorded significant success in handling medical and other complex classification tasks. However, as the sizes of DNN models and the available datasets increase, the training process becomes more complex and computationally intensive, usually taking longer to complete. In this work, we have proposed a generic full end-to-end hybrid parallelization approach combining model and data parallelism for efficiently distributed and scalable training of DNN models. We have also proposed a Genetic Algorithm Based Heuristic Resources Allocation (GABRA) mechanism for optimal distribution of partitions on the available GPUs for computing performance optimization. We have applied our proposed approach to a real use case based on 3D Residual Attention Deep Neural Network (3D-ResAttNet) for efficient Alzheimer Disease (AD) diagnosis on multiple GPUs and compared with the existing state-of-the-art parallel methods. The experimental evaluation shows that our proposed approach is 20% averagely better than existing parallel methods in terms of training time and achieves almost linear speedup with little or no differences in accuracy performance when compared with the existing non-parallel DNN models.},
  keywords={Computational modeling;Data models;Training;Resource management;Genetic algorithms;Computer architecture;Neural networks;Deep learning;genetic algorithm;data parallelization;model parallelization},
  doi={10.1109/ACCESS.2022.3193690},
  ISSN={2169-3536},
  month={},}@ARTICLE{10545647,
  author={Malu, G. and Uday, Nayana and Sherly, Elizabeth and Abraham, Ajith and Kuber Bodhey, Narendra},
  journal={IEEE Access}, 
  title={CirMNet: A Shape-Based Hybrid Feature Extraction Technique Using CNN and CMSMD for Alzheimer’s MRI Classification}, 
  year={2024},
  volume={12},
  number={},
  pages={80491-80504},
  abstract={This research introduces a novel approach called Circular Mesh Network (CirMNet), a shape-based hybrid feature extraction technique. It also proposes innovative Fractal Dimension (FD) and statistical feature extraction techniques for vertically symmetrical images. Convolutional Neural Networks (CNNs) have gained widespread popularity across various domains, including the interpretation of medical images. CNNs excel at extracting prominent features in the initial layers and progressively learn to capture more complex features as they advance. However, the pooling and striding operations involved in CNNs can lead to a loss of spatial and structural details in the image because CNNs require a mechanism to preserve the internal representation and describe the intricate relationships between image components or pixels. Circular Mesh-based Shape and Margin Descriptor (CMSMD) focuses on extracting structural, statistical, and property-based features. However, it does not encompass features such as texture or color. The objective of CirMNet is to leverage the strengths of both CNNs and CMSMD, and to mitigate their respective weaknesses. Structural and texture features were generated from CirMNet, and its performance was evaluated for the diagnosis of neurodegenerative disorders, particularly Alzheimer’s Disease (AD). The model can easily identify the permanent shrinkage and destruction of brain cells in MRIs of patients and exhibited a notable accuracy of 97.34% in classifying various stages of AD, encompassing Control, Early Mild Cognitive Impairment (EMCI), and Late Mild Cognitive Impairment (LMCI). This achievement represents a substantial improvement over the existing state-of-the-art methods in the domain.},
  keywords={Feature extraction;Convolutional neural networks;Shape;Magnetic resonance imaging;Convolution;Kernel;Graphics processing units;Alzheimer’s disease;magnetic resonance imaging;convolutional neural network;structural shapes;feature extraction},
  doi={10.1109/ACCESS.2024.3408311},
  ISSN={2169-3536},
  month={},}@ARTICLE{9515701,
  author={Deng, Hongxia and Zhang, Yuefang and Li, Ran and Hu, Chunxiang and Feng, Zijian and Li, Haifang},
  journal={Tsinghua Science and Technology}, 
  title={Combining residual attention mechanisms and generative adversarial networks for hippocampus segmentation}, 
  year={2022},
  volume={27},
  number={1},
  pages={68-78},
  abstract={This research discussed a deep learning method based on an improved generative adversarial network to segment the hippocampus. Different convolutional configurations were proposed to capture information obtained by a segmentation network. In addition, a generative adversarial network based on Pixel2Pixel was proposed. The generator was a codec structure combining a residual network and an attention mechanism to capture detailed information. The discriminator used a convolutional neural network to discriminate the segmentation results of the generated model and that of the expert. Through the continuously transmitted losses of the generator and discriminator, the generator reached the optimal state of hippocampus segmentation. T1-weighted magnetic resonance imaging scans and related hippocampus labels of 130 healthy subjects from the Alzheimer's disease Neuroimaging Initiative dataset were used as training and test data; similarity coefficient, sensitivity, and positive predictive value were used as evaluation indicators. Results showed that the network model could achieve an efficient automatic segmentation of the hippocampus and thus has practical relevance for the correct diagnosis of diseases, such as Alzheimer's disease.},
  keywords={Image segmentation;Hippocampus;Generative adversarial networks;Feature extraction;Training;Magnetic resonance imaging;Brain modeling;magnetic resonance imaging;generative adversarial network;residual network;attention mechanism},
  doi={10.26599/TST.2020.9010056},
  ISSN={1007-0214},
  month={Feb},}@ARTICLE{10857291,
  author={Babichev, Sergii and Liakh, Igor and Škvor, Jiří},
  journal={IEEE Access}, 
  title={Integrating Data Mining, Deep Learning, and Gene Ontology Analysis for Gene Expression-Based Disease Diagnosis Systems}, 
  year={2025},
  volume={13},
  number={},
  pages={21265-21278},
  abstract={The manuscript details the outcomes of a comprehensive study on the application of cluster-bicluster analysis, gene ontology analysis, and convolutional neural network (CNN) for diagnosing cancer and Alzheimer’s disease using gene expression data derived from both DNA microarray experiments and mRNA sequencing. It outlines a conceptual framework and provides a block diagram of the stepwise procedure for analyzing gene expression data, aiming to enhance the accuracy and objectivity of disease diagnosis. The research methodology involves initial gene ontology analysis, followed by the application of the Self Organizing Tree Algorithm (SOTA) for clustering gene expression profiles, an ensemble algorithm for data biclustering, and CNN for sample classification. Bayesian optimization method was employed to determine the optimal hyperparameters for all models. The analysis of simulation results demonstrates the high efficacy of the proposed approach. Specifically, for Alzheimer’s data, the number of genes analyzed was reduced from 44,662 to 4,004. Subsequent cluster-bicluster analysis divided this data into two subsets containing 1,158 and 2,846 genes, respectively. Classification accuracy for samples within these subsets reached 89.8% and 91.8%. In cancer data analysis, the gene count was reduced from 60,660 to 10,422, with 3,955 and 6,467 genes in the first and second clusters, respectively. The classification accuracy for these subsets was 97.4% and 97.6%, respectively. To our mind, the implementation of this model promises to significantly improve the efficacy of early diagnosis systems for complex diseases.},
  keywords={Gene expression;Ontologies;Accuracy;Optimization;Bayes methods;Medical diagnosis;Clustering algorithms;Alzheimer's disease;Predictive models;Precision medicine;Gene expression data;gene ontology analysis;clustering;biclustering;convolutional neural network;Bayes optimization;classification;Alzheimer’s disease;cancer disease},
  doi={10.1109/ACCESS.2025.3535999},
  ISSN={2169-3536},
  month={},}@ARTICLE{9618959,
  author={Arai, Hayato and Onga, Yuto and Ikuta, Kumpei and Chayama, Yusuke and Iyatomi, Hitoshi and Oishi, Kenichi},
  journal={IEEE Access}, 
  title={Disease-Oriented Image Embedding With Pseudo-Scanner Standardization for Content-Based Image Retrieval on 3D Brain MRI}, 
  year={2021},
  volume={9},
  number={},
  pages={165326-165340},
  abstract={To build a robust and practical content-based image retrieval (CBIR) system applicable to clinical brain MRI databases, we propose a new framework, disease-oriented image embedding with pseudo-scanner standardization (DI-PSS). It consists of two core techniques: data harmonization to absorb differences caused by different scanning environments and an algorithm to generate low-dimensional embeddings suitable for disease classification. Until now, there have been very few studies aimed at CBIR of brain MRI. Even in the harmonization of scanners, which is an important prerequisite technique for CBIR, only a limited number of studies have been conducted on T1-weighted MRI, which has collected a vast amount of clinical data. Recently proposed methods need to correctly estimate the domain (i.e., dataset, scanner) of each data in advance to remove environment-dependent information from low-dimensional embedding, which is not an easy task. With DI-PSS, each brain image is pseudo-transformed into a brain image taken with a given reference scanner. Then, 3D convolutional autoencoders (3D-CAE) trained with deep metric learning generate low-dimensional embeddings that better reflect the characteristics of the disease. In this study, DI-PSS reduced the variability of distance in low-dimensional embedding between Alzheimer’s disease (AD) and clinically normal (CN) patients, caused by differences in scanners and datasets, by 15.8-22.6% and 18.0-29.9%, respectively, compared to the baseline. This improved the ability of spectral clustering to classify AD and CN by 6.2% in average accuracy and 10.7% in macro-F1. Our method has the advantage of not requiring difficult domain prediction tasks in advance, and can effectively utilize the big data of T1-weighted MR images. Given the potential of the DI-PSS for harmonizing images scanned by MRI scanners that were not used to scan the training data, it is well suited for application to a large number of legacy MRIs captured in heterogeneous environments.},
  keywords={Magnetic resonance imaging;Diseases;Task analysis;Protocols;Databases;Standardization;Medical diagnostic imaging;ADNI;CBIR;convolutional auto encoders;CycleGAN;data harmonization;data standardization;metric learning;MRI;PPMI},
  doi={10.1109/ACCESS.2021.3129105},
  ISSN={2169-3536},
  month={},}@ARTICLE{10040684,
  author={Ngo, Thang and Pathirana, Pubudu N. and Horne, Malcolm K. and Corben, Louise A. and Harding, Ian H. and Szmulewicz, David J.},
  journal={IEEE Access}, 
  title={Technological Evolution in the Instrumentation of Ataxia Severity Measurement}, 
  year={2023},
  volume={11},
  number={},
  pages={14006-14027},
  abstract={Cerebellar ataxia is the poorly coordinated movement that results from injury or disease affecting the cerebellum. The diagnosis and assessment of ataxia are significantly challenging due to dependency on clinicians’ experience and the attendant subjectivity of such a process. In recent years, neuroimaging and sensor-based approaches, supported by effective machine learning techniques have made advances in the pursuit of addressing these clinical challenges. In this work, we present an outline of approaches to applying machine learning to this clinical challenge. We first provide a fundamental clinical overview with practical problems and then from a machine learning perspective, outline possible approaches with which to address these clinical challenges. Also discussed are the limitations in existing methods, the provision of cross disciplinary approaches and the current state-of-the-art as a potential basis for future research.},
  keywords={Pathology;Genetics;Cerebellum;Australia;Neurons;Machine learning;Neuroscience;Machine learning;Assistive technologies;Medical services;Cerebellar Ataxia;machine learning;medical applications;signal processing;diagnoses;severity estimation;assistive devices},
  doi={10.1109/ACCESS.2023.3243178},
  ISSN={2169-3536},
  month={},}@ARTICLE{9104657,
  author={Ramzan, Farheen and Khan, Muhammad Usman Ghani and Iqbal, Sajid and Saba, Tanzila and Rehman, Amjad},
  journal={IEEE Access}, 
  title={Volumetric Segmentation of Brain Regions From MRI Scans Using 3D Convolutional Neural Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={103697-103709},
  abstract={Automated brain segmentation is an active research domain due to the association of various neurological disorders with different regions of the brain, to help medical professionals in prognostics and diagnostics. Traditional techniques like atlas-based and pattern recognition-based methods led to the development of various tools for automated brain segmentation. Recently, deep learning techniques are outperforming classical state-of-the-art methods and gradually becoming more mature. Consequently, deep learning has been extensively employed as a tool for precise segmentation of brain regions because of its capability to learn the intricate features of the high-dimensional data. In this work, a network for the segmentation of multiple brain regions has been proposed that is based on 3D convolutional neural networks and utilizes residual learning and dilated convolution operations to efficiently learn the end-to-end mapping from MRI volumes to the voxel-level brain segments. This research is focused on the segmentation of up to nine brain regions including cerebrospinal fluid, white matter and gray matter as well as their sub-regions. Mean dice scores of 0.879 and 0.914 have been achieved for three and nine brain regions, respectively by using the data from three different sources. Comparative analysis shows that our network gives better dice scores for most of the brain regions than state-of-the-artwork. Moreover, the mean dice score of 0.903, obtained for eight brain regions segmentation with MRBrains18 dataset, is better than 0.876 which was achieved in the previous work.},
  keywords={Image segmentation;Three-dimensional displays;Deep learning;Magnetic resonance imaging;Task analysis;Two dimensional displays;Biomedical imaging;Brain segmentation;convolutional neural networks;magnetic resonance imaging;volumetric segmentation},
  doi={10.1109/ACCESS.2020.2998901},
  ISSN={2169-3536},
  month={},}@ARTICLE{10848369,
  author={Khalfallah, Souhaila and Puech, William and Tlija, Mehdi and Bouallegue, Kais},
  journal={IEEE Access}, 
  title={Exploring the Effectiveness of Machine Learning and Deep Learning Techniques for EEG Signal Classification in Neurological Disorders}, 
  year={2025},
  volume={13},
  number={},
  pages={17002-17015},
  abstract={Neurological disorders are among the leading causes of both physical and cognitive disabilities worldwide, affecting approximately 15% of the global population. This study explores the use of machine learning (ML) and deep learning (DL) techniques in processing Electroencephalography (EEG) signals to detect various neurological disorders, including Epilepsy, Autism Spectrum Disorder (ASD), and Alzheimer’s disease. We present a detailed workflow that begins with EEG data acquisition using a headset, followed by data preprocessing with Finite Impulse Response (FIR) filters and Independent Component Analysis (ICA) to eliminate noise and artifacts. Furthermore, the data is segmented, allowing the extraction of key features such as Bandpower and Shannon entropy, which improve classification accuracy. These features are stored in an offline database for easy access during analysis, to be then applied for both ML and DL models, systematically testing their performance and comparing the results to prior studies. Hence, our findings show impressive accuracy, with the random forest model achieving 99.85% accuracy in classifying autism vs. healthy subjects and 100% accuracy in distinguishing healthy individuals from those with dementia using Support Vector Machines (SVM). Moreover, deep learning models, including Convolutional Neural Networks (CNN) and ChronoNet, demonstrated accuracy rates ranging from 92.5% to 100%. In conclusion, this research highlights the effectiveness of ML and DL techniques in EEG signal processing, offering valuable contributions to the field of brain-computer interfaces and advancing the potential for more accurate neurological disease classification and diagnosis.},
  keywords={Electroencephalography;Recording;Accuracy;Neurological diseases;Brain modeling;Electrodes;Deep learning;Machine learning;Feature extraction;Autism;Electroencephalography (EEG);neurological disorders;machine learning;deep learning},
  doi={10.1109/ACCESS.2025.3532515},
  ISSN={2169-3536},
  month={},}@ARTICLE{9918050,
  author={Puri, Chetanya and Kooijman, Gerben and Vanrumste, Bart and Luca, Stijn},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Forecasting Time Series in Healthcare With Gaussian Processes and Dynamic Time Warping Based Subset Selection}, 
  year={2022},
  volume={26},
  number={12},
  pages={6126-6137},
  abstract={Modelling real-world time series can be challenging in the absence of sufficient data. Limited data in healthcare, can arise for several reasons, namely when the number of subjects is insufficient or the observed time series is irregularly sampled at a very low sampling frequency. This is especially true when attempting to develop personalised models, as there are typically few data points available for training from an individual subject. Furthermore, the need for early prediction (as is often the case in healthcare applications) amplifies the problem of limited availability of data. This article proposes a novel personalised technique that can be learned in the absence of sufficient data for early prediction in time series. Our novelty lies in the development of a subset selection approach to select time series that share temporal similarities with the time series of interest, commonly known as the test time series. Then, a Gaussian processes-based model is learned using the existing test data and the chosen subset to produce personalised predictions for the test subject. We will conduct experiments with univariate and multivariate data from real-world healthcare applications to show that our strategy outperforms the state-of-the-art by around 20%.},
  keywords={Time series analysis;Forecasting;Data models;Training data;Medical services;Gaussian processes;Machine learning;Forecasting;Gaussian processes;machine learning;time series analysis},
  doi={10.1109/JBHI.2022.3214343},
  ISSN={2168-2208},
  month={Dec},}@ARTICLE{10666721,
  author={Ozkan, Dilek and Katar, Oguzhan and Ak, Murat and Al-Antari, Mugahed A. and Yasan Ak, Nehir and Yildirim, Ozal and Mir, Hasan S. and Tan, Ru-San and Rajendra Acharya, U.},
  journal={IEEE Access}, 
  title={Deep Learning Techniques for Automated Dementia Diagnosis Using Neuroimaging Modalities: A Systematic Review}, 
  year={2024},
  volume={12},
  number={},
  pages={127879-127902},
  abstract={Dementia is a condition that often comes with aging and affects how people think, remember, and behave. Diagnosing dementia early is important because it can greatly improve patients’ lives. This systematic review looks at how deep learning (DL) techniques have been used to diagnose dementia automatically from 2012 to 2023. We explore how different DL methods like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Deep Neural Networks (DNN) are used to diagnose types of dementia such as Alzheimer’s, vascular dementia, and Lewy body dementia. We also discuss the difficulties of using DL for diagnosing dementia, like the lack of large and varied datasets and the challenge of applying models to different groups of people. These issues indicate the need for more dependable and understandable models that consider a wide range of patient characteristics and biomarkers. Longitudinal studies are also needed to understand how the disease progresses and how treatments work. Collaboration among researchers, doctors, and data scientists is crucial to ensure DL models are scientifically sound and effective in clinical settings. In summary, DL techniques show promise for automated dementia diagnosis and could improve how accurately and efficiently it is diagnosed in practice. However, further research is needed to address the challenges highlighted in this review.},
  keywords={Dementia;Neuroimaging;Deep learning;Positron emission tomography;Single photon emission computed tomography;Medical diagnostic imaging;Functional magnetic resonance imaging;Alzheimer's disease;Artificial neural networks;Alzheimer’s;deep learning;deep neural networks;disease classification;neuroimaging},
  doi={10.1109/ACCESS.2024.3454709},
  ISSN={2169-3536},
  month={},}@ARTICLE{10162210,
  author={Fay, Louisa and Cobos, Erick and Yang, Bin and Gatidis, Sergios and Küstner, Thomas},
  journal={IEEE Access}, 
  title={Avoiding Shortcut-Learning by Mutual Information Minimization in Deep Learning-Based Image Processing}, 
  year={2023},
  volume={11},
  number={},
  pages={64070-64086},
  abstract={Deep learning models are increasingly being used in detecting patterns and correlations in medical imaging data such as magnetic resonance imaging. However, conventional methods are incapable of considering the real underlying causal relationships. In the presence of confounders, spurious correlations between data, imaging process, content, and output can occur that allow the network to learn shortcuts instead of the desired causal relationship. This effect is even more prominent in new environments or when using out-of-distribution data since the learning process is primarily focused on correlations and patterns within the data. Hence, wrong conclusions or false diagnoses can be obtained from such confounded models. In this paper, we propose a novel framework, denoted as Mutual Information Minimization Model (MIMM), that predicts the desired causal outcome while simultaneously reducing the influence of present spurious correlations. The input imaging data is encoded into a feature vector that is split into two components to predict the primary task and the presumed spuriously correlated factor separately. We hypothesize that learned mutual information between both feature vector components can be reduced to achieve independence, i.e., confounder-free task prediction. The proposed approach is investigated on five databases: two non-medical benchmark databases (Morpho-MNIST and Fashion-MNIST) to verify the hypothesis and three medical databases (German National Cohort, UK Biobank, and ADNI). The results show that our proposed framework serves as a solution to address the limitations of conventional deep learning models in medical image analysis. By explicitly considering and minimizing spurious correlations, it learns causal relationships which result in more accurate and reliable predictions. The novel contributions in this work are: 1) the separation of features into the prediction of the primary task and the spuriously correlated factor; 2) MIMM targets the preservation of invariance to counterfactuals, prevents shortcut learning, and enables confounder-free network training; and 3) the mutual information minimization addresses heterogeneous data cohorts as usually encountered in the medical domain.},
  keywords={Correlation;Learning systems;Mutual information;Deep learning;Predictive models;Databases;Data models;Biomedical imaging;Causality;deep learning;medical image analysis;mutual information;shortcut learning},
  doi={10.1109/ACCESS.2023.3289397},
  ISSN={2169-3536},
  month={},}@ARTICLE{10763483,
  author={Shubar, Abduelhakem G. and Ramakrishnan, Kannan and Ho, Chin-Kuan},
  journal={IEEE Access}, 
  title={Optimizing Machine Learning Models for Accessible Early Cognitive Impairment Prediction: A Novel Cost-Effective Model Selection Algorithm}, 
  year={2024},
  volume={12},
  number={},
  pages={180792-180814},
  abstract={Cognitive impairment and dementia-related diseases develop several years before moderate or severe deterioration in cognitive function occurs. Nevertheless, most dementia cases, especially in low- and middle-income countries, remain undiagnosed because of limited access to affordable diagnostic tools. Additionally, the development of accessible tools for diagnosing and predicting cognitive impairment has not been extensively discussed in the literature. The objective of this study is to develop a cost-effective and highly accessible machine learning model to predict the risk of cognitive impairment for up to five years before clinical insight. We utilized easily accessible data from the National Alzheimer’s Coordinating Center (NACC) Uniform Data Set (UDS) to train and evaluate various machine learning and deep learning models. A novel algorithm was developed to facilitate the selection of cost-effective models that offer high performance while minimizing development and operational costs. We conducted various assessments, including feature selection, time-series analyses, and external validation of the selected model. Our findings indicated that the Support Vector Machine (SVM) model was preferred over other high-performing neural network models because of its computational efficiency, achieving F2-scores of 0.828 in cross-validation and 0.750 in a generalizability test. Additionally, we found that demographic and historical health data are valuable for early prediction of cognitive impairment. This study demonstrates the potential of developing accessible solutions to predict cognitive impairment early using accurate and efficient machine learning models. Future interventions should consider creating cost-effective assessment tools to support global action plans and reduce the risk of cognitive impairment.},
  keywords={Accuracy;Predictive models;Machine learning;Machine learning algorithms;Diseases;Data models;Brain modeling;Neuroimaging;Medical diagnostic imaging;Alzheimer's disease;Cognitive impairment;cost-effective models;dementia;early prediction;machine learning;model selection},
  doi={10.1109/ACCESS.2024.3505038},
  ISSN={2169-3536},
  month={},}@ARTICLE{11079564,
  author={Dogan, Bedriye and Burak Mutlu, Hursit and Yildirim, Muhammed and Yalcin, Sercan and Aslan, Serpil and Sampathila, Niranjana and Yildirim, Ozal and Ciaccio, Edward J. and Tan, Ru-San and Rajendra Acharya, U.},
  journal={IEEE Access}, 
  title={Content-Based Brain Magnetic Resonance Image Retrieval and Classification With the Proposed Deep Learning and Tissue-Based System}, 
  year={2025},
  volume={13},
  number={},
  pages={122684-122697},
  abstract={The exponential growth in the size of databases due to technological advancements has led to challenges in locating and accessing specific components of the data. While deep learning and other machine learning architectures have shown promise in retrieving data components, their efficacy is more pronounced when addressing disease cohorts. Contrarily, this effectiveness diminishes when accessing large datasets. This study focuses on the analysis of brain magnetic resonance imaging (MRI) images and, specifically, to differentiate between benign and malignant lesions associated with Alzheimer’s disease, multiple sclerosis (MS), and intracranial regions, all of which are medically significant with distinct treatment modalities. A hybrid model was first devised to facilitate image retrieval by employing a pre-trained EfficientNet-b0 and local binary pattern (LBP) for feature extraction. These extracted features were then amalgamated to encompass diverse aspects of each image. To improve model performance, redundant features were pruned using the minimum redundancy maximum relevance (mRMR) technique. As a result, the proposed model demonstrated efficacy in analyzing a diverse dataset encompassing three distinct diseases and eight unique classes. Notably, existing machine architectures already published in the literature have struggled to achieve comparable success rates in discerning such closely related yet distinct disease groups. Our study underscores the challenge posed by increasing class diversity on the performance of deep learning architectures and obtained an accuracy of 98.9% in classifying three diseases and eight unique classes. As a result, the same model was used as the base in both the classification and CBIR processes for MRI detection, yielding competitive results when compared with the literature and other models.},
  keywords={Feature extraction;Diseases;Mathematical models;Magnetic resonance imaging;Brain modeling;Alzheimer's disease;Training;Computer architecture;Accuracy;Multiple sclerosis;Alzheimer;brain tumor;classification;multiple sclerosis;retrieval},
  doi={10.1109/ACCESS.2025.3588211},
  ISSN={2169-3536},
  month={},}@ARTICLE{9580859,
  author={Kim, Seong Tae and Küçükaslan, Umut and Navab, Nassir},
  journal={IEEE Access}, 
  title={Longitudinal Brain MR Image Modeling Using Personalized Memory for Alzheimer’s Disease}, 
  year={2021},
  volume={9},
  number={},
  pages={143212-143221},
  abstract={Longitudinal analysis of a disease is an important issue to understand its progression and design prognosis and early diagnostic tools. From the longitudinal images where data is collected from multiple time points, both the spatial structural information and the longitudinal variations are captured. The temporal dynamics are more informative than static observations of the symptoms, particularly for neurodegenerative diseases such as Alzheimer’s disease, whose progression spans over the years with early subtle changes. In this paper, we propose a new generative framework to predict the lesion progression over time. Our method first encodes images into the structural and longitudinal state vectors, where interpolation or extrapolation of feature vectors in the time axis can be performed for the manipulation of these feature vectors. These processed feature vectors can be decoded into image space to predict the image at the time point which we are interested in. During the training, we force the model to encode longitudinal changes into longitudinal state features and capture the structural information in a separate vector. Moreover, we introduce a personalized memory for the online update scheme, which adapts the model to the target subject, which helps the model preserve fine details of brain image structures in each subject. Experimental results on the public longitudinal brain magnetic resonance imaging dataset show the effectiveness of the proposed method.},
  keywords={Diseases;Brain modeling;Alzheimer's disease;Adaptation models;Training;Interpolation;Decoding;Brain MR images;deep learning;generative model;longitudinal analysis;personalized prediction;memory network},
  doi={10.1109/ACCESS.2021.3121609},
  ISSN={2169-3536},
  month={},}@ARTICLE{11071277,
  author={Alharthi, Abdullah S. and Alqurashi, Ahmed and Essa Alharbi, Turki and Alammar, Mohammed M. and Aldosari, Nasser and Bouchekara, Houssem R. E. H. and Sha’aban, Yusuf A. and Shoaib Shahriar, Mohammad and Al Ayidh, Abdulrahman},
  journal={IEEE Access}, 
  title={Explainable AI for Sensor Signal Interpretation to Revolutionize Human Health Monitoring: A Review}, 
  year={2025},
  volume={13},
  number={},
  pages={115990-116024},
  abstract={The complexity of sensor signal patterns in healthcare, coupled with the variability of physiological data present significant challenges in developing reliable diagnostic and monitoring. While machine learning (ML) has greatly advanced sensor-based health analysis, its decision-making processes often lack transparency, raising concerns about reliability and clinical adoption. This review explores the role of Explainable Artificial Intelligence (XAI) in enhancing the interpretability of ML models for sensor signal analysis, particularly in applications such as pressure sensors, wearable inertial sensors, imaging sensors (MRI, CT, X-ray), ECG, EEG, and wearable health tracking. A systematic literature review was conducted across multiple databases to identify studies applying XAI techniques to sensor-based health monitoring. The review categorizes nine trending XAI methods used to interpret ML-driven analyses of biosignals, evaluating their advantages and limitations in different healthcare scenarios. The findings emphasize the importance of transparency in ML-driven sensor analysis, which is critical for building trust and real-time clinical decision-making and wearable healthcare applications. Despite its potential, XAI for sensor signals faces challenges related to model scalability, real-time processing, and clinician interpretability. The review identifies key research gaps in integrating XAI into sensor-based healthcare systems, emphasizing the need for robust validation methods and user-friendly explanations. Ultimately, XAI offers a promising path toward revolutionizing sensor-driven health monitoring, though further advancements are necessary to fully integrate explainability into real-world clinical and assistive applications.},
  keywords={Medical services;Monitoring;Explainable AI;Diseases;Robot sensing systems;Reviews;Biomedical monitoring;Prediction algorithms;Machine learning;Accuracy;Explainable AI human health;gait;Parkinson’s disease;stroke;depression;cancer;heart disease;Alzheimer’s disease},
  doi={10.1109/ACCESS.2025.3585764},
  ISSN={2169-3536},
  month={},}@ARTICLE{9787553,
  author={Mwamsojo, Nickson and Lehmann, Frederic and El-Yacoubi, Mounim A. and Merghem, Kamel and Frignac, Yann and Benkelfat, Badr-Eddine and Rigaud, Anne-Sophie},
  journal={IEEE Access}, 
  title={Reservoir Computing for Early Stage Alzheimer’s Disease Detection}, 
  year={2022},
  volume={10},
  number={},
  pages={59821-59831},
  abstract={Artificial Neural Networks (ANNs) have amassed unprecedented success in information processing ranging from image recognition to time series prediction. The success can largely be attributed to the availability of large datasets for training and the increased complexity of the models. Unfortunately, for some applications only a limited amount of samples is available for training. Fewer training samples increases the risk of over-fitting and poor generalization especially in high complexity models. Moreover, complex models with a large number of trainable parameters require more energy to train and optimize compared to simpler ones. In this paper, to the best of our knowledge, we propose the first use of ANNs for Early Stage Alzheimer Disease classification (ES-AD) from the handwriting (HW). We propose using a framework for building Recurrent Neural Networks (RNNs) known as Reservoir Computing (RC), both numerically and experimentally, that simplifies training by optimizing the output layer only. We also propose the Bidirectional Long Term Short Term (BiLSTM) and Convolutional Neural Network (CNN) methods for comparison. For a fairer comparison, we not only consider the accuracies but also the energy costs incurred to obtain the respective accuracies in order to assess the accuracy-efficiency trade-off. Our numerical and experimental results show that RC yields a classification accuracy of 85%, which is 3% worse than that of BiLSTM and 2% better than that of CNN, at a relatively lower training and significantly lower inference costs. We hope that our findings highlight the importance of examining the accuracy-efficiency trade-off of various models in the community in order to reduce the overall impact of ANNs training on the environment.},
  keywords={Training;Alzheimer's disease;Task analysis;Costs;Reservoirs;Convolutional neural networks;Recurrent neural networks;Alzheimer’s;artificial neural networks;handwriting;reservoir computing;green AI},
  doi={10.1109/ACCESS.2022.3180045},
  ISSN={2169-3536},
  month={},}@ARTICLE{10964250,
  author={Ho Kim, Kyeong and Kim, Minji and Kim, Sohui and Lee, Jong-Min},
  journal={IEEE Access}, 
  title={Enhancing Genomic Data Representation Through BERT-LSTM Hybrid Architecture}, 
  year={2025},
  volume={13},
  number={},
  pages={76497-76507},
  abstract={This study proposes a novel approach for effective genetic sequence representation, focusing on the challenges of compressing and analyzing complex genomic data. We introduce a hybrid architecture that combines Bidirectional Encoder Representations from Transformers (BERT) with Long Short-Term Memory (LSTM) networks to generate comprehensive and compact gene embeddings. Our method processes genetic sequence data through k-mer tokenization and employs BERT to capture complex patterns, followed by LSTM to preserve essential sequential information while creating fixed-size representations. Using data from 623 participants from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database, we analyzed genetic sequences across 10 genes to evaluate our approach. The effectiveness of our method is demonstrated through both visualization and quantitative evaluation. The t-distributed stochastic neighbor embedding (t-SNE) visualization revealed improved clustering of gene embeddings compared to traditional approaches, while our model achieved 82% accuracy in gene classification tasks. Our findings indicate that the combination of BERT and LSTM effectively captures both local and global genetic patterns while creating meaningful compressed representations, providing a promising framework for genetic sequence analysis.},
  keywords={Genetics;Genomics;Bioinformatics;Transformers;Long short term memory;Tokenization;Encoding;Bidirectional control;Data models;Sequences;BERT;gene embedding;LSTM;representation learning;SNP;tokenization},
  doi={10.1109/ACCESS.2025.3560282},
  ISSN={2169-3536},
  month={},}@ARTICLE{9284503,
  author={Ma, Yuhui and Hao, Huaying and Xie, Jianyang and Fu, Huazhu and Zhang, Jiong and Yang, Jianlong and Wang, Zhen and Liu, Jiang and Zheng, Yalin and Zhao, Yitian},
  journal={IEEE Transactions on Medical Imaging}, 
  title={ROSE: A Retinal OCT-Angiography Vessel Segmentation Dataset and New Model}, 
  year={2021},
  volume={40},
  number={3},
  pages={928-939},
  abstract={Optical Coherence Tomography Angiography (OCTA) is a non-invasive imaging technique that has been increasingly used to image the retinal vasculature at capillary level resolution. However, automated segmentation of retinal vessels in OCTA has been under-studied due to various challenges such as low capillary visibility and high vessel complexity, despite its significance in understanding many vision-related diseases. In addition, there is no publicly available OCTA dataset with manually graded vessels for training and validation of segmentation algorithms. To address these issues, for the first time in the field of retinal image analysis we construct a dedicated Retinal OCTA SEgmentation dataset (ROSE), which consists of 229 OCTA images with vessel annotations at either centerline-level or pixel level. This dataset with the source code has been released for public access to assist researchers in the community in undertaking research in related topics. Secondly, we introduce a novel split-based coarse-to-fine vessel segmentation network for OCTA images (OCTA-Net), with the ability to detect thick and thin vessels separately. In the OCTA-Net, a split-based coarse segmentation module is first utilized to produce a preliminary confidence map of vessels, and a split-based refined segmentation module is then used to optimize the shape/contour of the retinal microvasculature. We perform a thorough evaluation of the state-of-the-art vessel segmentation models and our OCTA-Net on the constructed ROSE dataset. The experimental results demonstrate that our OCTA-Net yields better vessel segmentation performance in OCTA than both traditional and other deep learning methods. In addition, we provide a fractal dimension analysis on the segmented microvasculature, and the statistical analysis demonstrates significant differences between the healthy control and Alzheimer's Disease group. This consolidates that the analysis of retinal microvasculature may offer a new scheme to study various neurodegenerative diseases.},
  keywords={Measurement;Image segmentation;Statistical analysis;Optical coherence tomography;Ultraviolet sources;Retina;Diseases;Optical coherence tomography angiography;vessel segmentation;deep network;benchmark},
  doi={10.1109/TMI.2020.3042802},
  ISSN={1558-254X},
  month={March},}@ARTICLE{9766171,
  author={Lai, Zhengfeng and Oliveira, Luca Cerny and Guo, Runlin and Xu, Wenda and Hu, Zin and Mifflin, Kelsey and Decarli, Charles and Cheung, Sen-Ching and Chuah, Chen-Nee and Dugger, Brittany N.},
  journal={IEEE Access}, 
  title={BrainSec: Automated Brain Tissue Segmentation Pipeline for Scalable Neuropathological Analysis}, 
  year={2022},
  volume={10},
  number={},
  pages={49064-49079},
  abstract={As neurodegenerative disease pathological hallmarks have been reported in both grey matter (GM) and white matter (WM) with different density distributions, automating the segmentation process of GM/WM would be extremely advantageous for aiding in neuropathologic deep phenotyping. Standard segmentation methods typically involve manual annotations, where a trained researcher traces the delineation of GM/WM in ultra-high-resolution Whole Slide Images (WSIs). This method can be time-consuming and subjective, preventing a scalable analysis on pathology images. This paper proposes an automated segmentation pipeline (BrainSec) combining a Convolutional Neural Network (CNN) module for segmenting GM/WM regions and a post-processing module to remove artifacts/residues of tissues. The final output generates XML annotations that can be visualized via Aperio ImageScope. First, we investigate two baseline models for medical image segmentation: FCN, and U-Net. Then we propose a patch-based approach, BrainSec, to classify the GM/WM/background regions. We demonstrate BrainSec is robust and has reliable performance by testing it on over 180 WSIs that incorporate numerous unique cases as well as distinct neuroanatomic brain regions. We also apply gradient-weighted class activation mapping (Grad-CAM) to interpret the segmentation masks and provide relevant explanations and insights. In addition, we have integrated BrainSec with an existing Amyloid- $\beta $  pathology classification model into a unified framework (without incurring significant computation complexity) to identify pathologies, visualize their distributions, and quantify each type of pathologies in segmented GM/WM regions, respectively.},
  keywords={Image segmentation;Diseases;Pipelines;Convolutional neural networks;Brain modeling;Image resolution;Annotations;Neuropathology;machine learning;medical image analysis;convolutional neural network;Alzheimer’s disease;dementia},
  doi={10.1109/ACCESS.2022.3171927},
  ISSN={2169-3536},
  month={},}@ARTICLE{10400467,
  author={Gajjar, Pranshav and Garg, Manav and Desai, Shivani and Chhinkaniwala, Hitesh and Sanghvi, Harshal A. and Patel, Riki H. and Gupta, Shailesh and Pandya, Abhijit S.},
  journal={IEEE Access}, 
  title={An Empirical Analysis of Diffusion, Autoencoders, and Adversarial Deep Learning Models for Predicting Dementia Using High-Fidelity MRI}, 
  year={2024},
  volume={12},
  number={},
  pages={131231-131243},
  abstract={This study explores cutting-edge computational technologies and intelligent methods to create realistic synthetic data, focusing on dementia-centric Magnetic Resonance Imaging (MRI) scans related to Alzheimer’s and Parkinson’s diseases. The research delves into Generative Adversarial Networks (GANs), Variational Autoencoders, and Diffusion Models, comparing their efficacy in generating synthetic MRI scans. Using datasets from Alzheimer’s and Parkinson’s patients, the study reveals intriguing findings. In the Alzheimer dataset, diffusion models produced non-dementia images with the lowest Frechet Inception Distance (FID) score at 92.46, while data-efficient GANs excelled in generating dementia images with an FID score of 178.53. In the Parkinson dataset, data-efficient GANs achieved remarkable FID scores of 102.71 for dementia images and 129.77 for non-dementia images. The study also introduces a novel aspect by incorporating a classification study, validating the generative metrics. DenseNets, a deep learning architecture, exhibited superior performance in disease detection compared to ResNets. Training both models on images generated by diffusion models further improved results, with DenseNet achieving accuracies of 80.84% and 92.42% in Alzheimer’s and Parkinson’s disease detection, respectively. The research not only presents innovative generative architectures but also emphasizes the importance of classification metrics, providing valuable insights into the synthesis and detection of neurodegenerative diseases through advanced computational techniques.},
  keywords={Data models;Generative adversarial networks;Magnetic resonance imaging;Deep learning;Brain modeling;Alzheimer's disease;Diffusion processes;Biomedical computing;Diffusion models;data augmentation;biomedical deep learning;dementia;generative adversarial networks},
  doi={10.1109/ACCESS.2024.3354724},
  ISSN={2169-3536},
  month={},}@ARTICLE{9035446,
  author={Oh, Kanghan and Kim, Sungchan and Oh, Il-Seok},
  journal={IEEE Access}, 
  title={Salient Explanation for Fine-Grained Classification}, 
  year={2020},
  volume={8},
  number={},
  pages={61433-61441},
  abstract={Explaining the prediction of deep models has gained increasing attention to increase its applicability, even spreading it to life-affecting decisions. However there has been no attempt to pinpoint only the most discriminative features contributing specifically to separating different classes in a fine-grained classification task. This paper introduces a novel notion of salient explanation and proposes a simple yet effective salient explanation method called Gaussian light and shadow (GLAS), which estimates the spatial impact of deep models by the feature perturbation inspired by light and shadow in nature. GLAS provides a useful coarse-to-fine control benefiting from scalability of Gaussian mask. We also devised the ability to identify multiple instances through recursive GLAS. We prove the effectiveness of GLAS for fine-grained classification using the fine-grained classification dataset. To show the general applicability, we also illustrate that GLAS has state-of-the-art performance at high speed (about 0.5 sec per  $224\times 224$  image) via the ImageNet Large Scale Visual Recognition Challenge.},
  keywords={Perturbation methods;Task analysis;Visualization;Scalability;Face;Birds;Neurons;Computer vision;neural networks;explainable artificial intelligence;machine learning},
  doi={10.1109/ACCESS.2020.2980742},
  ISSN={2169-3536},
  month={},}@ARTICLE{9459113,
  author={Syed, Zafi Sherhan and Syed, Muhammad Shehram Shah and Lech, Margaret and Pirogova, Elena},
  journal={IEEE Access}, 
  title={Automated Recognition of Alzheimer’s Dementia Using Bag-of-Deep-Features and Model Ensembling}, 
  year={2021},
  volume={9},
  number={},
  pages={88377-88390},
  abstract={Alzheimer’s dementia is a progressive neurodegenerative disease that causes cognitive and physical impairment. It severely deteriorates the quality of life in affected individuals. An early diagnosis can assist immensely in better management of their healthcare needs. In recent years, there has been a renewed impetus in development of automated methods for recognition of various disorders by leveraging advancements in artificial intelligence. Here, we propose a multimodal system that can identify linguistic and paralinguistic traits of dementia using an automated screening tool. We show that bag-of-deep-neural-embeddings and ensemble learning offer a viable approach to objective assessment of dementia. The developed system is tested on the Alzheimer’s Dementia Recognition Challenge dataset, where it achieved a new state-of-the-art (SOTA) performance for the classification task and matched the current SOTA for the regression task. These results highlight the efficacy of our proposed system for facilitating an early diagnosis of dementia.},
  keywords={Task analysis;Alzheimer's disease;Acoustics;Speech recognition;Medical diagnostic imaging;Bit error rate;Alzheimer’s dementia recognition;deep neural embeddings;multi-model fusion;social signal processing},
  doi={10.1109/ACCESS.2021.3090321},
  ISSN={2169-3536},
  month={},}@ARTICLE{11052217,
  author={Patro, Peetabas and Das, Tapan Kumar},
  journal={IEEE Access}, 
  title={Artificial Intelligence in Action (2019-2024): A Review on Parkinson’s Disease Detection Using Non-Invasive Procedures}, 
  year={2025},
  volume={13},
  number={},
  pages={116586-116605},
  abstract={Alzheimer’s disease, Parkinson’s disease (PD), multiple sclerosis, epilepsy, and stroke are among the most significant neurological disorders. This paper focuses on PD. Although there is currently no cure for PD, early identification can help manage the condition. We present a comprehensive review of cutting-edge research on computerized methods for detecting and monitoring Parkinson’s disease. Our study covers various feature extraction techniques, methods for reducing dimensionality, feature selection approaches, and classification strategies related to PD. The articles reviewed were chosen from various journals, from January 2019 to September 2024, based on the data sources and symptoms used to diagnose PD. We conducted a thorough analysis and documented information about datasets, software tools, and libraries for future use of researchers in this field.},
  keywords={Diseases;Motors;Systematic literature review;Neurological diseases;Magnetic resonance imaging;Deep learning;Databases;Rigidity;Muscles;Monitoring;Neurological disorder;Parkinson’s disease;deep learning;non-invasive technique;machine learning},
  doi={10.1109/ACCESS.2025.3583572},
  ISSN={2169-3536},
  month={},}@ARTICLE{9003258,
  author={Song, Xuegang and Elazab, Ahmed and Zhang, Yuexin},
  journal={IEEE Access}, 
  title={Classification of Mild Cognitive Impairment Based on a Combined High-Order Network and Graph Convolutional Network}, 
  year={2020},
  volume={8},
  number={},
  pages={42816-42827},
  abstract={Detection of early stages of Alzheimer's disease (AD) (i.e., mild cognitive impairment (MCI)) is important because it can delay or prevent progression to AD. The current researches of MCI classification are mainly based on static low-order functional connectivity network (FCN) and image information. However, static FCN cannot reflect time-varying dynamic behavior, low-order FCN overlooks inter-region interactions, and ignoring non-image information is not suitable especially when the size of dataset is small. In this paper, a method based on a combined high-order network and graph convolutional network (GCN) is proposed. The combined high-order network combines static, dynamic and high-level information to construct FCN while GCN is used to include non-image information to improve classifier's performance. Firstly, dynamic FCNs and static FCN are constructed by using a sliding window approach. Secondly, dynamic high-order FCNs and static high-order FCN based on the topographical similarity are then constructed. Thirdly, a novel combination method is proposed to utilize dynamic high-order FCNs and static high-order FCN to form a combined high-order FCN. Fourthly, features of the combined high-order FCNs are extracted by using a recursive feature elimination method. Lastly, after inputting extracted features into the GCN, in which MCI-graph establishes interactions between individuals and populations by using non-image information, the GCN outputs the binary classification results. Experimental results on Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset (adni.loni.ucla.edu) show that our framework has good performance.},
  keywords={Feature extraction;Microsoft Windows;Time series analysis;Windows;Diseases;Sociology;Mild cognitive impairment;binary classification;combined high-order network;graph convolutional network},
  doi={10.1109/ACCESS.2020.2974997},
  ISSN={2169-3536},
  month={},}@ARTICLE{9039644,
  author={Raj, R. Joshua Samuel and Shobana, S. Jeya and Pustokhina, Irina Valeryevna and Pustokhin, Denis Alexandrovich and Gupta, Deepak and Shankar, K.},
  journal={IEEE Access}, 
  title={Optimal Feature Selection-Based Medical Image Classification Using Deep Learning Model in Internet of Medical Things}, 
  year={2020},
  volume={8},
  number={},
  pages={58006-58017},
  abstract={Internet of Medical Things (IoMT) is the collection of medical devices and related applications which link the healthcare IT systems through online computer networks. In the field of diagnosis, medical image classification plays an important role in prediction and early diagnosis of critical diseases. Medical images form an indispensable part of a patient's health record which can be applied to control, handle and treat the diseases. But, classification of images is a challenging task in computer-based diagnostics. In this research article, we have introduced a improved classifier i.e., Optimal Deep Learning (DL) for classification of lung cancer, brain image, and Alzheimer's disease. The researchers proposed the Optimal Feature Selection based Medical Image Classification using DL model by incorporating preprocessing, feature selection and classification. The main goal of the paper is to derive an optimal feature selection model for effective medical image classification. To enhance the performance of the DL classifier, Opposition-based Crow Search (OCS) algorithm is proposed. The OCS algorithm picks the optimal features from pre-processed images, here Multi-texture, grey level features were selected for the analysis. Finally, the optimal features improved the classification result and increased the accuracy, specificity and sensitivity in the diagnosis of medical images. The proposed results were implemented in MATLAB and compared with existing feature selection models and other classification approaches. The proposed model achieved the maximum performance in terms of accuracy, sensitivity and specificity being 95.22%, 86.45 % and 100% for the applied set of images.},
  keywords={Medical diagnostic imaging;Feature extraction;Deep learning;Solid modeling;Cancer;IoMT;classification;deep learning;medical image;features;Crow search algorithm;optimization},
  doi={10.1109/ACCESS.2020.2981337},
  ISSN={2169-3536},
  month={},}@ARTICLE{9439485,
  author={Cilia, Nicole Dalia and De Stefano, Claudio and Fontanella, Francesco and Freca, Alessandra Scotto Di},
  journal={IEEE Access}, 
  title={Feature Selection as a Tool to Support the Diagnosis of Cognitive Impairments Through Handwriting Analysis}, 
  year={2021},
  volume={9},
  number={},
  pages={78226-78240},
  abstract={Cognitive Impairments are cognitive deficits that are greater than expected for a person of a given age and level of education, but which do not significantly interfere with the daily life of the people affected. They range from mild to severe and are seen as a risk factor for Alzheimer's disease, currently the most common neurodegenerative brain disorder worldwide. In a previous study, we presented an experimental protocol comprising different handwriting tasks to be carried out by patients and a healthy control group: the aim was to investigate whether the analysis of the handwriting could be used as a tool to support the diagnosis of this kind of impairment. In the study presented here, we used a well-known and widely-used feature selection approach to determine the most effective features for predicting the symptoms related to cognitive impairments via handwriting analysis. Our intention is to deepen the knowledge about the different cognitive functions affected by the onset of these diseases, as well as to improve the performance of the tools developed to support their diagnosis. The results showed that different sets of highly discriminant features, closely related to the cognitive skills impaired, were selected for the handwriting tasks making up the protocol, thus supporting our hypothesis that their use can be very helpful to support the diagnosis of cognitive impairment.},
  keywords={Feature extraction;Task analysis;Protocols;Tools;Frequency measurement;Data mining;Frequency control;Medical expert systems;cognitive impairments;feature selection},
  doi={10.1109/ACCESS.2021.3083176},
  ISSN={2169-3536},
  month={},}@ARTICLE{10634155,
  author={Pacheco-Lorenzo, Moisés R. and Christensen, Heidi and Anido-Rifón, Luis E. and Fernández-Iglesias, Manuel J. and Valladares-Rodríguez, Sonia M.},
  journal={IEEE Access}, 
  title={Analysis of Voice Biomarkers for the Detection of Cognitive Impairment}, 
  year={2024},
  volume={12},
  number={},
  pages={122840-122851},
  abstract={The objective of this work is to determine whether speech obtained from interactions with a smart speaker can be used to predict the level of cognitive impairment (CI). We use a voice assistant to administer a cognitive test in Spanish, and we record the conversations in order to extract features that could potentially be used as voice biomarkers. A total of 21 participants (14 patients and 7 healthy controls) between the ages of 68 and 86 are included in the study (15 were women). Using just speech we are able to perform a regression with machine learning models, in order to predict the Global Deterioration Scale (GDS) of cognitive functions. Then, we measure the performance of the estimations with standard metrics - an  $R^{2}$  of 0.74 was obtained in the best case using Support Vector Machine (SVM) algorithms. Despite needing a bigger sample of participants in future studies, this is a positive and promising result for such a non-intrusive procedure, which could potentially be used as a screening tool for automatic cognitive impairment assessment.},
  keywords={Feature extraction;Task analysis;Alzheimer's disease;Biomarkers;Accuracy;Oral communication;Support vector machines;Biomarkers;Dementia;Regression analysis;Speech recognition;Biomarkers;cognitive impairment;dementia;regression;voice},
  doi={10.1109/ACCESS.2024.3442431},
  ISSN={2169-3536},
  month={},}@ARTICLE{10844538,
  author={Condado, Jorge Garcia and Tellaetxe-Elorriaga, Iñigo and Cortes, Jesus M. and Erramuzpe, Asier},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={AgeML: Age Modeling With Machine Learning}, 
  year={2025},
  volume={29},
  number={5},
  pages={3772-3781},
  abstract={An approach to age modeling involves the supervised prediction of age using machine learning from subject features. The derived age metrics are used to study the relationship between healthy and pathological aging in multiple body systems, as well as the interactions between them. We lack a standard for this type of age modeling. In this work we developed AgeML, an OpenSource software for age-prediction from any type of tabular clinical data following well-established and tested methodologies. The objective is to set standards for reproducibility and standardization of reporting in supervised age modeling tasks. AgeML does age modeling, calculates age deltas, the difference between predicted and chronological age, measures correlations between age deltas and factors, visualizes differences in age deltas of different clinical populations and classifies clinical populations based on age deltas. With this software we are able to reproduce published work and unveil novel relationships between body organs and polygenetic risk scores. AgeML is age modeling made easy for standardization and reproducibility.},
  keywords={Brain modeling;Diseases;Biological systems;Standards;Reproducibility of results;Machine learning;Data models;Phenotypes;Bioinformatics;Predictive models;Brain age;aging;machine learning;open source;standardization;reproducibility;polygenetic risk scores},
  doi={10.1109/JBHI.2025.3531017},
  ISSN={2168-2208},
  month={May},}@ARTICLE{10614199,
  author={Wang, Xuan and Yang, Xiaopeng and Zhang, Xiaotong and Chen, Yang},
  journal={IEEE Access}, 
  title={ROI-Based Multimodal Neuroimaging Feature Fusion Method and Its Graph Neural Network Diagnostic Model}, 
  year={2025},
  volume={13},
  number={},
  pages={26915-26926},
  abstract={Single-modality neuroimaging data often provide limited information and are constrained by technical issues such as signal-to-noise ratio, and resolution limitations, potentially leading to biases and an incomplete understanding of brain complexities. This can hinder the development of diagnostic and therapeutic strategies for brain disorders. To address these challenges, this paper presents the Multimodal Graph Neural Network Model based on Feature Fusion (MMP-DGNN), which leverages sMRI and PET data. The model employs an algorithm to extract and accurately describe sample features using an autoencoder. During feature fusion, a shared adjacency matrix based on feature similarity and phenotypic data is constructed for graph representation. A dual-layer graph neural network then classifies the features, with the results fused at the decision layer for final classification. Experimental results show that MMP-DGNN achieves superior classification performance of 98.17%, outperforming other methods in multimodal neuroimaging data classification.},
  keywords={Feature extraction;Neuroimaging;Databases;Brain modeling;Data models;Grey matter;Sociology;Multimodal sensors;Graph neural networks;Multimodal neuroimaging data;feature fusion;graph neural networks;feature matrix based on ROIs},
  doi={10.1109/ACCESS.2024.3435433},
  ISSN={2169-3536},
  month={},}@ARTICLE{9093026,
  author={Basher, Abol and Kim, Byeong C. and Lee, Kun Ho and Jung, Ho Yub},
  journal={IEEE Access}, 
  title={Automatic Localization and Discrete Volume Measurements of Hippocampi From MRI Data Using a Convolutional Neural Network}, 
  year={2020},
  volume={8},
  number={},
  pages={91725-91739},
  abstract={Automatic hippocampal volume measurement from brain magnetic resonance imaging (MRI) is a crucial task and an important research area, especially in the study of neurodegenerative diseases; hippocampal volume atrophy is known to be connected with Alzheimer's disease. In this research work, we propose a deep learning-based method to automatically measure the discrete hippocampal volume without prior segmentation of the volumetric MRI scans. We constructed a 2-D convolutional neural network (CNN) model that uses 3-channel 2-D patches to predict the number of voxels attributed to the hippocampus; the number of estimated hippocampal voxels is multiplied by the voxel volume to measure the discrete volume of the hippocampus. In addition, we demonstrate a preprocessing scheme to prepare the data using a relatively small number of MRI scans. The average errors in the measured volumes of the proposed approach and the compared atlas-based system were 4.3173 ± 3.5436 (avg. error% ± STD) and 4.1562 ±3.5262 (avg. error % ± STD) for the left and right hippocampi, respectively. The correlation coefficients of the proposed approach with atlas-based volume measurement were statistically significant (p-value <; 0.01, R2 = 0.834 (left hippocampus), and R2 = 0.848 (right hippocampus) based on 0.05 significance level), which suggests that the proposed approach can be used as a proxy method for the atlas-based system. Furthermore, the proposed approach is computationally efficient and requires less than 2 seconds to calculate the number of voxels for an MRI scan. Moreover, our method outperforms the state-of-the-art deep learning approach, such as 2-D U-Net and SegNet in the context of voxel/volume estimation errors% for the left and right hippocampi.},
  keywords={Magnetic resonance imaging;Volume measurement;Hippocampus;Dementia;Image segmentation;Machine learning;MRI;hippocampus;patch;Hough-CNN;localization;CNN;discrete volume},
  doi={10.1109/ACCESS.2020.2994388},
  ISSN={2169-3536},
  month={},}@ARTICLE{10829922,
  author={Suliman Farhan, Ahmeed and Khalid, Muhammad and Manzoor, Umar},
  journal={IEEE Access}, 
  title={Combined Oriented Data Augmentation Method for Brain MRI Images}, 
  year={2025},
  volume={13},
  number={},
  pages={9981-9994},
  abstract={In recent years, deep learning’s use in medical imaging has grown exponentially. However, one of the biggest problems with training deep learning models is the unavailability of large amounts of data, which leads to overfitting. Collecting large quantities of labelled medical images is expensive, time-consuming, and depends on specialists’ availability. In this paper, we proposed a novel method namely Oriented Combination MRI (OCMRI) for augmenting brain MRI dataset. The proposed method helps CNN models overcome overfitting and address class imbalance issues by combining Brain MRI images to generate new images. The image fusion is performed by selecting two images of the same tumor class if the Mean Squared Error (MSE) between these two images is greater than threshold 1 and lower than threshold 2. Both thresholds are adjustable, initially set by the user and automatically fine-tuned by the algorithm to control the number of images produced for each class, thus helping to address the data imbalance problem. The proposed approach was evaluated by training and testing the PRCnet model on four publicly available datasets before and after applying the proposed method to the datasets. Where the classification accuracy without data augmentation was 85.19% for dataset A, 90.12% for dataset B, 94.77% for dataset C, and 90% for dataset D respectively. After adding the synthetic data; the accuracy improved to 92.7% for dataset A, 95.37% for dataset B, 96.51% for dataset C and 98% for dataset D respectively.},
  keywords={Deep learning;Training;Accuracy;Magnetic resonance imaging;Brain modeling;Data augmentation;Data models;Overfitting;Biomedical imaging;Tumors;Data augmentation;brain tumor;medical imaging;deep learning;MRI;brain tumor classification;convolutional neural network},
  doi={10.1109/ACCESS.2025.3526684},
  ISSN={2169-3536},
  month={},}@ARTICLE{10016237,
  author={Nguyen, Kevin P. and Treacher, Alex H. and Montillo, Albert A.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Adversarially-Regularized Mixed Effects Deep Learning (ARMED) Models Improve Interpretability, Performance, and Generalization on Clustered (non-iid) Data}, 
  year={2023},
  volume={45},
  number={7},
  pages={8081-8093},
  abstract={Natural science datasets frequently violate assumptions of independence. Samples may be clustered (e.g., by study site, subject, or experimental batch), leading to spurious associations, poor model fitting, and confounded analyses. While largely unaddressed in deep learning, this problem has been handled in the statistics community through mixed effects models, which separate cluster-invariant fixed effects from cluster-specific random effects. We propose a general-purpose framework for Adversarially-Regularized Mixed Effects Deep learning (ARMED) models through non-intrusive additions to existing neural networks: 1) an adversarial classifier constraining the original model to learn only cluster-invariant features, 2) a random effects subnetwork capturing cluster-specific features, and 3) an approach to apply random effects to clusters unseen during training. We apply ARMED to dense, convolutional, and autoencoder neural networks on 4 datasets including simulated nonlinear data, dementia prognosis and diagnosis, and live-cell image analysis. Compared to prior techniques, ARMED models better distinguish confounded from true associations in simulations and learn more biologically plausible features in clinical applications. They can also quantify inter-cluster variance and visualize cluster effects in data. Finally, ARMED matches or improves performance on data from clusters seen during training (5-28% relative improvement) and generalization to unseen clusters (2-9% relative improvement) versus conventional models.},
  keywords={Data models;Biological system modeling;Deep learning;Adaptation models;Training;Predictive models;Bayes methods;Generalization;interpretability;mixed effects model;multilevel model;biomedical imaging;clinical data},
  doi={10.1109/TPAMI.2023.3234291},
  ISSN={1939-3539},
  month={July},}@ARTICLE{10244037,
  author={Gende, Mateo and Mallen, Víctor and de Moura, Joaquim and Cordón, Beatriz and Garcia-Martin, Elena and Sánchez, Clara I. and Novo, Jorge and Ortega, Marcos},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Automatic Segmentation of Retinal Layers in Multiple Neurodegenerative Disorder Scenarios}, 
  year={2023},
  volume={27},
  number={11},
  pages={5483-5494},
  abstract={Retinal Optical Coherence Tomography (OCT) allows the non-invasive direct observation of the central nervous system, enabling the measurement and extraction of biomarkers from neural tissue that can be helpful in the assessment of ocular, systemic and Neurological Disorders (ND). Deep learning models can be trained to segment the retinal layers for biomarker extraction. However, the onset of ND can have an impact on the neural tissue, which can lead to the degraded performance of models not exposed to images displaying signs of disease during training. We present a fully automatic approach for the retinal layer segmentation in multiple neurodegenerative disorder scenarios, using an annotated dataset of patients of the most prevalent NDs: Alzheimer's disease, Parkinson's disease, multiple sclerosis and essential tremor, along with healthy control patients. Furthermore, we present a two-part, comprehensive study on the effects of ND on the performance of these models. The results show that images of healthy patients may not be sufficient for the robust training of automated segmentation models intended for the analysis of ND patients, and that using images representative of different NDs can increase the model performance. These results indicate that the presence or absence of patients of ND in datasets should be taken into account when training deep learning models for retinal layer segmentation, and that the proposed approach can provide a valuable tool for the robust and reliable diagnosis in multiple scenarios of ND.},
  keywords={Retina;Image segmentation;Diseases;Visualization;Training;Deep learning;Data models;Deep learning;medical image segmentation;neurological disease;optical coherence tomography;retina},
  doi={10.1109/JBHI.2023.3313392},
  ISSN={2168-2208},
  month={Nov},}@ARTICLE{10179861,
  author={Jui, S. Janifer Jabin and Deo, Ravinesh C. and Barua, Prabal Datta and Devi, Aruna and Soar, Jeffrey and Acharya, U. Rajendra},
  journal={IEEE Access}, 
  title={Application of Entropy for Automated Detection of Neurological Disorders With Electroencephalogram Signals: A Review of the Last Decade (2012–2022)}, 
  year={2023},
  volume={11},
  number={},
  pages={71905-71924},
  abstract={An automated Neurological Disorder detection system can be considered as a cost-effective and resource efficient tool for medical and healthcare applications. In automated Neurological Disorder detection, electroencephalograms are commonly used, but their low signal intensity and nonlinear features are difficult to analyze visually. A promising approach for processing of electroencephalogram signals is the concept of entropy, a nonlinear signal processing method to measure the chaos in the signal. The aim of this study was to find out the effective entropy measures and the machine learning approaches that produced promising output. Using Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines as our method, we have identified 84 studies published between 2012 and 2022 that has investigated epilepsy, Parkinson’s disease, autism, Attention Deficit Hyperactive disorder, schizophrenia, Alzheimer’s disease, depression, and alcohol use disorder with machine learning approaches considering entropy measures. We show that Support Vector Machines was the most commonly used machine learning model, with consistent performance in most of the studies whereas sample entropy was the most commonly used entropy measure, followed by the approximate entropy. For epilepsy detection, the most used entropy feature was the log energy entropy, whereas the multi-scale entropy was commonly used for Alzheimer’s Disease, approximate and sample entropy used for Parkinson’s Disease, multi scale and Shannon entropy applied for autism, approximate and Shannon entropy used for attention deficit hyperactive disorder, sample entropy used for depression, approximate and spectral entropy adopted for schizophrenia, and the approximate and sample entropy employed for alcohol use disorder. According to the majority of the studies, there is growing concern about the increase in neuro patients and the heavy resource burden that is associated with their prevalence and diagnosis. Based on these studies, we conclude that Computer-Aided Design systems would be economically advantageous in detecting Neurological Disorders. To incorporate Computer-Aided Design system into the mainstream health care system, future research could focus on multi-modal approaches to the disorder and its interpretation and explanation. We believe this is the first review that has combined the electroencephalograms, entropy, and automated detection possibility of the 8 distinct neurological disorders. The study is limited to the papers that used accuracy as their performance evaluation metric. The findings and synthesis of previous studies provides a clear pathway that identifies the entropy approach as a practical solution for automated detection of neurological disorder using electroencephalograms with potential applications in other kinds of signal analysis.},
  keywords={Entropy;Neurological diseases;Electroencephalography;Mental disorders;Epilepsy;Autism;Australia;Machine learning;Neurological disorder;entropy;automated detection;EEG;artificial intelligence;machine},
  doi={10.1109/ACCESS.2023.3294473},
  ISSN={2169-3536},
  month={},}@ARTICLE{10758629,
  author={Ahmed Mohamed, Alshaymaa and Saleh, Yasmine N. M. and Abdel-Hamid, Ayman A.},
  journal={IEEE Access}, 
  title={OptiSGD-DPWGAN: Integrating Metaheuristic Algorithms and Differential Privacy to Improve Privacy-Utility Trade-Off in Generative Models}, 
  year={2024},
  volume={12},
  number={},
  pages={176070-176086},
  abstract={Recently, the necessity to balance model performance with data confidentiality in synthetic data generation has become a significant challenge in deep learning analysis of medical databases. In this paper, the OptiSGD-DPWGAN model is proposed, that incorporates metaheuristic algorithms and differential privacy into the Wasserstein Generative Adversarial Network (WGAN) architecture to protect sensitive data during the training process. The integration of Simulated Annealing and Backtracking Line Search with Stochastic Gradient Descent (SGD) optimizes the exploration of the solution space of complex parameters in non-convex deep learning models, significantly avoiding local minima. In differentially private synthetic data generation, adjusting the epsilon value critically influences the trade-off between preserving privacy and maintaining the utility of the data. Typically, a lower epsilon value strengthens privacy guarantees but can inversely affect the model’s effectiveness due to increased noise in the data processing. Empirical results demonstrate that OptiSGD-DPWGAN effectively mitigates this trade-off. Compared to other schemes, OptiSGD-DPWGAN consistently achieves lower privacy costs without compromising the quality of the synthetic data generated. These results not only show the capability of OptiSGD-DPWGAN to set a new standard in privacy-preserving synthetic data generation but also highlight its potential to generate high-quality synthetic data crucial for the medical domain which requires strict confidentiality and high precision.},
  keywords={Privacy;Differential privacy;Noise;Deep learning;Data models;Training;Synthetic data;Generative adversarial networks;Computational modeling;Protection;Differential privacy;deep learning;generative adversarial network;privacy-utility tradeoff;stochastic gradient descent},
  doi={10.1109/ACCESS.2024.3502909},
  ISSN={2169-3536},
  month={},}@ARTICLE{9146821,
  author={Kim, Kookjin and Lee, Seungjin and Kim, Sungjoong and Kim, Jaekeun and Shin, Dongil and Shin, Dongkyoo},
  journal={IEEE Access}, 
  title={Sensor-Based Deviant Behavior Detection System Using Deep Learning to Help Dementia Caregivers}, 
  year={2020},
  volume={8},
  number={},
  pages={136004-136013},
  abstract={The number of elderly people suffering from dementia, a senile disease, is increasing day by day due to the rapid aging of the population. As a result, social and economic costs are also gradually increasing. To prevent such monetary losses, a system that can operate at a low cost is needed to care for dementia patients. Therefore, this research proposes a sensor-based deviant behavior detection system that allows caregivers to easily manage dementia patients even if they are not in the same location as their dementia patients at a low cost. In this research, the autoencoder and the LSTM models were used together, because deviance behavior is difficult to obtain labeled data. The autoencoder model is a representative unsupervised learning model, which can be used to extract characteristics of data, and was used to learn characteristics of normal behavioral data. The LSTM model is used to determine the deviant behavior from output outlier data that exceeds the threshold in the autoencoder. As a result of the experiment, each model achieved more than 96% and more than 99% accuracy. This research is expected to help caregivers of dementia patients manage the elderly with dementia more inexpensively and efficiently.},
  keywords={Hidden Markov models;Dementia;Data models;Senior citizens;Biological system modeling;Statistics;Deviant detection;deep-learning;autoencoder;long short-term memory models},
  doi={10.1109/ACCESS.2020.3011654},
  ISSN={2169-3536},
  month={},}@ARTICLE{10916656,
  author={Atoar Rahman, S. M. and Ibrahim Khalil, Md and Zhou, Hui and Guo, Yu and Ding, Ziyun and Gao, Xin and Zhang, Dingguo},
  journal={IEEE Access}, 
  title={Advancement in Graph Neural Networks for EEG Signal Analysis and Application: A Review}, 
  year={2025},
  volume={13},
  number={},
  pages={50167-50187},
  abstract={Electroencephalography (EEG) can non-invasively measure neuronal events and reflect brain activity at different locations on the scalp. Early studies for EEG signal processing have focused more on extracting EEG temporal features and considered the topology of EEG channels less due to the limitation of rich spatial information. Graph neural networks (GNNs), as a new kind of deep learning method, can use EEG signals as graph vertices, capturing the hidden topological connections between signals. GNNs have made great progress in EEG studies due to the advantage. In this overview, we review the very new and fundamental models of GNNs and their modifications, such as graph regularized neural networks, graph convolutional neural networks, spatial-temporal graph neural networks, graph attention networks, and their variants in EEG signal analysis fields. The applications of GNNs are summarized in the domains of emotion detection, epilepsy seizure detection, stroke rehabilitation, Alzheimer’s disease diagnosis, motor imagery detection, neurological disease diagnosis, major depressive disorder, and driving fatigue detection. We employed a Systematic Literature Review (SLR) approach to select 79 papers for a comprehensive review. The current state is analyzed and forecasts are provided based on the available difficulties. We conclude by suggesting potential directions for future research in this rapidly developing topic.},
  keywords={Electroencephalography;Graph neural networks;Systematic literature review;Brain modeling;Quality assessment;Feature extraction;Deep learning;Signal analysis;Convolution;Standards;Electroencephalogram;deep learning;graph neural networks;variants of graph neural networks;applications of graph neural network},
  doi={10.1109/ACCESS.2025.3549120},
  ISSN={2169-3536},
  month={},}@ARTICLE{9769980,
  author={Ilias, Loukas and Askounis, Dimitris},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Explainable Identification of Dementia From Transcripts Using Transformer Networks}, 
  year={2022},
  volume={26},
  number={8},
  pages={4153-4164},
  abstract={Alzheimer’s disease (AD) is the main cause of dementia which is accompanied by loss of memory and may lead to severe consequences in peoples’ everyday life if not diagnosed on time. Very few works have exploited transformer-based networks and despite the high accuracy achieved, little work has been done in terms of model interpretability. In addition, although Mini-Mental State Exam (MMSE) scores are inextricably linked with the identification of dementia, research works face the task of dementia identification and the task of the prediction of MMSE scores as two separate tasks. In order to address these limitations, we employ several transformer-based models, with BERT achieving the highest accuracy accounting for 87.50%. Concurrently, we propose an interpretable method to detect AD patients based on siamese networks reaching accuracy up to 83.75%. Next, we introduce two multi-task learning models, where the main task refers to the identification of dementia (binary classification), while the auxiliary one corresponds to the identification of the severity of dementia (multiclass classification). Our model obtains accuracy equal to 86.25% on the detection of AD patients in the multi-task learning setting. Finally, we present some new methods to identify the linguistic patterns used by AD patients and non-AD ones, including text statistics, vocabulary uniqueness, word usage, correlations via a detailed linguistic analysis, and explainability techniques (LIME). Findings indicate significant differences in language between AD and non-AD patients.},
  keywords={Dementia;Feature extraction;Task analysis;Transformers;Bit error rate;Multitasking;Deep learning;Alzheimer’s disease;dementia;BERT;multi-task learning;LIME},
  doi={10.1109/JBHI.2022.3172479},
  ISSN={2168-2208},
  month={Aug},}@ARTICLE{9506846,
  author={Górriz, J. M. and Jiménez-Mesa, C. and Segovia, F. and Ramírez, J. and SiPBA Group and Suckling, J.},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={A Connection Between Pattern Classification by Machine Learning and Statistical Inference With the General Linear Model}, 
  year={2022},
  volume={26},
  number={11},
  pages={5332-5343},
  abstract={A connection between the general linear model (GLM) with frequentist statistical testing and machine learning (MLE) inference is derived and illustrated. Initially, the estimation of GLM parameters is expressed as a Linear Regression Model (LRM) of an indicator matrix; that is, in terms of the inverse problem of regressing the observations. Both approaches, i.e. GLM and LRM, apply to different domains, the observation and the label domains, and are linked by a normalization value in the least-squares solution. Subsequently, we derive a more refined predictive statistical test: the linear Support Vector Machine (SVM), that maximizes the class margin of separation within a permutation analysis. This MLE-based inference employs a residual score and associated upper bound to compute a better estimation of the actual (real) error. Experimental results demonstrate how parameter estimations derived from each model result in different classification performance in the equivalent inverse problem. Moreover, using real data, the MLE-based inference including model-free estimators demonstrates an efficient trade-off between type I errors and statistical power.},
  keywords={Maximum likelihood estimation;Mathematical model;Probability;Linear regression;Bioinformatics;Neuroimaging;Predictive models;General linear model;Linear Regression Model;pattern classification;upper bounds;permutation tests;cross-validation},
  doi={10.1109/JBHI.2021.3101662},
  ISSN={2168-2208},
  month={Nov},}@ARTICLE{9535529,
  author={Xia, Zhengwang and Zhou, Tao and Mamoon, Saqib and Lu, Jianfeng},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Recognition of Dementia Biomarkers With Deep Finer-DBN}, 
  year={2021},
  volume={29},
  number={},
  pages={1926-1935},
  abstract={The treatment of neurodegenerative diseases is expensive, and long-term treatment makes families bear a heavy burden. Accumulating evidence suggests that the high conversion rate can possibly be reduced if clinical interventions are applied at the early stage of brain diseases. Thus, a variety of deep learning methods are utilized to recognize the early stages of neurodegenerative diseases for clinical intervention and treatment. However, most existing methods have ignored the issue of sample imbalance, which often makes it difficult to train an effective model due to lack of a large number of negative samples. To address this problem, we propose a two-stage method, which is used to learn the compression and recover rules of normal subjects so that potential negative samples can be detected. The experimental results show that the proposed method can not only obtain a superb recognition result, but also give an explanation that conforms to the physiological mechanism. Most importantly, the deep learning model does not need to be retrained for each type of disease, which can be widely applied to the diagnosis of various brain diseases. Furthermore, this research could have great potential in understanding regional dysfunction of various brain diseases.},
  keywords={Feature extraction;Brain modeling;Training;Functional magnetic resonance imaging;Data models;Deep learning;Convolution;Alzheimer’s disease (AD);deep learning;fMRI classification;sample imbalance},
  doi={10.1109/TNSRE.2021.3111989},
  ISSN={1558-0210},
  month={},}@ARTICLE{10026289,
  author={Wu, Zhenpeng and Zheng, Jiantao and Liu, Jiashu and Lin, Cuixiang and Li, Hong-Dong},
  journal={Big Data Mining and Analytics}, 
  title={DeepRetention: A Deep Learning Approach for Intron Retention Detection}, 
  year={2023},
  volume={6},
  number={2},
  pages={115-126},
  abstract={As the least understood mode of alternative splicing, Intron Retention (IR) is emerging as an interesting area and has attracted more and more attention in the field of gene regulation and disease studies. Existing methods detect IR exclusively based on one or a few predefined metrics describing local or summarized characteristics of retained introns. These metrics are not able to describe the pattern of sequencing depth of intronic reads, which is an intuitive and informative characteristic of retained introns. We hypothesize that incorporating the distribution pattern of intronic reads will improve the accuracy of IR detection. Here we present DeepRetention, a novel approach for IR detection by modeling the pattern of sequencing depth of introns. Due to the lack of a gold standard dataset of IR, we first compare DeepRetention with two state-of-the-art methods, i.e. iREAD and IRFinder, on simulated RNA-seq datasets with retained introns. The results show that DeepRetention outperforms these two methods. Next, DeepRetention performs well when it is applied to third-generation long-read RNA-seq data, while IRFinder and iREAD are not applicable to detecting IR from the third-generation sequencing data. Further, we show that IRs predicted by DeepRetention are biologically meaningful on an RNA-seq dataset from Alzheimer's Disease (AD) samples. The differential IRs are found to be significantly associated with AD based on statistical evaluation of an AD-specific functional gene network. The parent genes of differential IRs are enriched in AD-related functions. In summary, DeepRetention detects IR from a new angle of view, providing a valuable tool for IR analysis.},
  keywords={Measurement;Deep learning;Sequential analysis;Convolution;Splicing;Training data;Brain modeling;Alternative Splicing (AS);Intron Retention (IR);intronic reads distribution pattern;RNA-seq},
  doi={10.26599/BDMA.2022.9020023},
  ISSN={2097-406X},
  month={June},}@ARTICLE{10373947,
  author={Tawhid, Md. Nurul Ahad and Siuly, Siuly and Kabir, Enamul and Li, Yan},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Exploring Frequency Band-Based Biomarkers of EEG Signals for Mild Cognitive Impairment Detection}, 
  year={2024},
  volume={32},
  number={},
  pages={189-199},
  abstract={Mild Cognitive Impairment (MCI) is often considered a precursor to Alzheimer’s disease (AD), with a high likelihood of progression. Accurate and timely diagnosis of MCI is essential for halting the progression of AD and other forms of dementia. Electroencephalography (EEG) is the prevalent method for identifying MCI biomarkers. Frequency band-based EEG biomarkers are crucial for identifying MCI as they capture neuronal activities and connectivity patterns linked to cognitive functions. However, traditional approaches struggle to identify precise frequency band-based biomarkers for MCI diagnosis. To address this challenge, a novel framework has been developed for identifying important frequency sub-bands within EEG signals for MCI detection. In the proposed scheme, the signals are first denoised using a stationary wavelet transformation and segmented into small time frames. Then, four frequency sub-bands are extracted from each segment, and spectrogram images are generated for each sub-band as well as for the full filtered frequency band signal segments. This process produces five different sets of images for five separate frequency bands. Afterwards, a convolutional neural network is used individually on those image sets to perform the classification task. Finally, the obtained results for the tested four sub-bands are compared with the results obtained using the full bandwidth. Our proposed framework was tested on two MCI datasets, and the results indicate that the 16–32 Hz sub-band range has the greatest impact on MCI detection, followed by 4–8 Hz. Furthermore, our framework, utilizing the full frequency band, outperformed existing state-of-the-art methods, indicating its potential for developing diagnostic tools for MCI detection.},
  keywords={Electroencephalography;Spectrogram;Time-frequency analysis;Biomarkers;Image segmentation;Australia;Feature extraction;CNN;deep learning;electroencephalogram (EEG);frequency sub-band;mild cognitive impairment (MCI);spectrogram},
  doi={10.1109/TNSRE.2023.3347032},
  ISSN={1558-0210},
  month={},}@ARTICLE{10552388,
  author={Sajid, M. and Tanveer, M. and Suganthan, Ponnuthurai N.},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Ensemble Deep Random Vector Functional Link Neural Network Based on Fuzzy Inference System}, 
  year={2025},
  volume={33},
  number={1},
  pages={479-490},
  abstract={The ensemble deep random vector functional link (edRVFL) neural network has demonstrated the ability to address the limitations of conventional artificial neural networks. However, since edRVFL generates features for its hidden layers through random projection, it can potentially lose intricate features or fail to capture certain nonlinear features in its base models (hidden layers). To enhance the feature learning capabilities of edRVFL, we propose a novel edRVFL based on fuzzy inference system (edRVFL-FIS). The proposed edRVFL-FIS leverages the capabilities of two emerging domains, namely deep learning and ensemble approaches, with the intrinsic IF–THEN properties of FIS and produces rich feature representation to train the ensemble model. Each base model of the proposed edRVFL-FIS encompasses the following two key feature augmentation components: 1) unsupervised fuzzy layer features and 2) supervised defuzzified features. The edRVFL-FIS model incorporates diverse clustering methods (R-means, K-means, fuzzy C-means) to establish fuzzy layer rules, resulting in the following three model variations: 1) edRVFL-FIS-R, 2) edRVFL-FIS-K, and 3) edRVFL-FIS-C with distinct fuzzified features and defuzzified features. Within the framework of edRVFL-FIS, each base model utilizes the original, hidden layer, and defuzzified features to make predictions. Experimental results, statistical tests, discussions, and analyses conducted across UCI and NDC datasets consistently demonstrate the superior performance of all variations of the proposed edRVFL-FIS model over baseline models such as fuzzy broad learning system.},
  keywords={Brain modeling;Mathematical models;Vectors;Training;Computational modeling;Fuzzy systems;Deep learning;Big data;broad learning system;deep learning;ensemble deep random vector functional link (edRVFL);ensemble learning;fuzzy broad learning system;fuzzy inference system (FIS);random vector functional link (RVFL) network},
  doi={10.1109/TFUZZ.2024.3411614},
  ISSN={1941-0034},
  month={Jan},}@ARTICLE{10984423,
  author={Azad, Reza and Dehghanmanshadi, Mohammad and Khosravi, Nika and Cohen-Adad, Julien and Merhof, Dorit},
  journal={Computational Visual Media}, 
  title={Addressing Missing Modality Challenges in MRI Images: A Comprehensive Review}, 
  year={2025},
  volume={11},
  number={2},
  pages={241-268},
  abstract={Magnetic resonance imaging (MRI) is one of the most prevalent imaging modalities used for diagnosis, treatment planning, and outcome control in various medical conditions. MRI sequences provide physicians with the ability to view and monitor tissues at multiple contrasts within a single scan and serve as input for automated systems to perform downstream tasks. However, in clinical practice, there is usually no concise set of identically acquired sequences for a whole group of patients. As a consequence, medical professionals and automated systems both face difficulties due to the lack of complementary information from such missing sequences. This problem is well known in computer vision, particularly in medical image processing tasks such as tumor segmentation, tissue classification, and image generation. With the aim of helping researchers, this literature review examines a significant number of recent approaches that attempt to mitigate these problems. Basic techniques such as early synthesis methods, as well as later approaches that deploy deep learning, such as common latent space models, knowledge distillation networks, mutual information maximization, and generative adversarial networks (GANs) are examined in detail. We investigate the novelty, strengths, and weaknesses of the aforementioned strategies. Moreover, using a case study on the segmentation task, our survey offers quantitative benchmarks to further analyze the effectiveness of these methods for addressing the missing modalities challenge. Furthermore, a discussion offers possible future research directions.},
  keywords={Surveys;Knowledge engineering;Deep learning;Image segmentation;Visualization;Magnetic resonance imaging;Benchmark testing;Mutual information;Faces;Tumors;missing modality;survey;deep learning;magnetic resonance imaging (MRI)},
  doi={10.26599/CVM.2025.9450399},
  ISSN={2096-0662},
  month={April},}@ARTICLE{10015102,
  author={Zhang, Chutian and Yang, Hongjun and Fan, Chen-Chen and Chen, Sheng and Fan, Chenyu and Hou, Zeng-Guang and Chen, Jingyao and Peng, Liang and Xiang, Kexin and Wu, Yi and Xie, Hongyu},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Comparing Multi-Dimensional fNIRS Features Using Bayesian Optimization-Based Neural Networks for Mild Cognitive Impairment (MCI) Detection}, 
  year={2023},
  volume={31},
  number={},
  pages={1019-1029},
  abstract={The diagnosis of mild cognitive impairment (MCI), a prodromal stage of Alzheimer’s disease (AD), is essential for initiating timely treatment to delay the onset of AD. Previous studies have shown the potential of functional near-infrared spectroscopy (fNIRS) for diagnosing MCI. However, preprocessing fNIRS measurements requires extensive experience to identify poor-quality segments. Moreover, few studies have explored how proper multi-dimensional fNIRS features influence the classification results of the disease. Thus, this study outlined a streamlined fNIRS preprocessing method to process fNIRS measurements and compared multi-dimensional fNIRS features with neural networks in order to explore how temporal and spatial factors affect the classification of MCI and cognitive normality. More specifically, this study proposed using Bayesian optimization-based auto hyperparameter tuning neural networks to evaluate 1D channel-wise, 2D spatial, and 3D spatiotemporal features of fNIRS measurements for detecting MCI patients. The highest test accuracies of 70.83%, 76.92%, and 80.77% were achieved for 1D, 2D, and 3D features, respectively. Through extensive comparisons, the 3D time-point oxyhemoglobin feature was proven to be a more promising fNIRS feature for detecting MCI by using an fNIRS dataset of 127 participants. Furthermore, this study presented a potential approach for fNIRS data processing, and the designed models required no manual hyperparameter tuning, which promoted the general utilization of fNIRS modality with neural network-based classification to detect MCI.},
  keywords={Functional near-infrared spectroscopy;Three-dimensional displays;Feature extraction;Convolutional neural networks;Electroencephalography;Task analysis;Fans;Convolutional neural networks (CNN);functional near-infrared spectroscopy (fNIRS);mild cognitive impairment (MCI);multi-dimensional feature evaluation;multilayer perceptron (MLP)},
  doi={10.1109/TNSRE.2023.3236007},
  ISSN={1558-0210},
  month={},}@ARTICLE{9734022,
  author={Sohail, Nosheen and Anwar, Syed Muhammad},
  journal={IEEE Access}, 
  title={A Modified U-Net Based Framework for Automated Segmentation of Hippocampus Region in Brain MRI}, 
  year={2022},
  volume={10},
  number={},
  pages={31201-31209},
  abstract={An accurate localization of the brain anatomical structure for correct and reliable diagnostic strategies is of great concern in many bio-medical applications. Towards this end, manual or semi-automated delineation methods used are found to be time consuming. Herein, to address this problem, we present an enhanced model for automated segmentation of two neighboring small structures of the brain in the Hippocampus region i.e., anterior and posterior. Our aim is to improve the segmentation performance, where the proposed architecture captures contextual information in encoding path and enables precise localization by utilizing the decoding path in a symmetric way. In particular, our proposed methodology enhances the original U-Net architecture with 3-dimensional (3D) data processing and employs spatial elastic deformation. Further, we evaluated the segmentation performance using recursive U-Net for comparison. The effectiveness of different optimization strategies are evaluated on a publicly available data comprising of 3D magnetic resonance imaging volumes from mono-modal hippocampus region. Our experimental results demonstrate the robustness of the proposed model by using patch-based augmentation technique for hippocampal segmentation.},
  keywords={Image segmentation;Hippocampus;Magnetic resonance imaging;Object oriented modeling;Deep learning;Solid modeling;Brain modeling;Augmentation;deep learning;localization;magnetic resonance imaging;segmentation;U-net},
  doi={10.1109/ACCESS.2022.3159618},
  ISSN={2169-3536},
  month={},}@ARTICLE{9611247,
  author={Jain, Varun and Nankar, Om and Jerrish, Daryl Jacob and Gite, Shilpa and Patil, Shruti and Kotecha, Ketan},
  journal={IEEE Access}, 
  title={A Novel AI-Based System for Detection and Severity Prediction of Dementia Using MRI}, 
  year={2021},
  volume={9},
  number={},
  pages={154324-154346},
  abstract={Dementia is a symptom of Alzheimer’s Disease (A.D.) that affects many people around the globe each year. There is no effective cure to treat this disease, and it can prove to be deadly to the patient if left untreated or undetected. In this paper, the authors propose a novel DCGAN-based Augmentation and Classification (D-BAC) model approach to identify and classify dementia into various categories depending upon its prominence and severity in the available MRI scans. The proposed detection of early onset of dementia, also referred to as Mild Cognitive Impairment (MCI), is also studied with the help of a novel GAN-augmented dataset. The proposed model can predict MCI with an accuracy of 74% and can classify dementia into four categories depending upon its prominence in the MRI scan. The authors have also utilized Visual Explainable A.I. (XAI) and have used GradCAM to visually represent the internal working of the model. This novel approach helps verify the differentiating features of the MRI scans learned by the CNN model during training. Three different datasets, namely the original dataset, geometrically transformed images, and a GAN-augmented dataset, have been used for performance analysis. A comparison of the performance of the CNN model has been made on these datasets, and the superiority of results using the novel GAN-augmented dataset has been studied and discussed. Moreover, progressive resizing has also been applied on this GAN-dataset, and different CNN architectures have also been used to achieve better performance scores. The model proposed in the end has a training accuracy of 97% and a testing accuracy of 82% when tested using a conventional CNN architecture and has a testing accuracy of 84% and 87% when tested using VGG-16 and VGG-19 architecture, respectively.},
  keywords={Dementia;Magnetic resonance imaging;Senior citizens;Convolutional neural networks;Biomedical imaging;Predictive models;Feature extraction;Augmentation;dementia;generative adversarial networks;magnetic resonance imaging;mild cognitive impairment},
  doi={10.1109/ACCESS.2021.3127394},
  ISSN={2169-3536},
  month={},}@ARTICLE{11124828,
  author={Nagajyothi, Dhulipalla and Chirra, Venkata Rami Reddy},
  journal={IEEE Access}, 
  title={Optimized Quantum CNN With Improvised iHow Algorithm for MRI-Based Dementia Diagnosis}, 
  year={2025},
  volume={13},
  number={},
  pages={148128-148144},
  abstract={Dementia, a neurodegenerative disorder, requires early prediction and effective diagnosis for providing better treatment to avert the loss. The detection and classification of disease is intricate and needs optimized solutions using deep learning techniques. In context with this, the proposed work presents a novel approach with the inclusion of an Optimized Quantum Convolutional Neural Network (Q-CNN). The optimization algorithm utilized is the Improved iHow Optimization Algorithm (IiHOA), which fine-tunes the hyper-parameters in the proposed Q-CNN. Moreover, the MRI images are pre-processed with the combined act of B-spline and Lanczos Interpolation by removing the noises and preserving the sensitive details. This enhances the image quality and can be used to extract features. For feature extraction, U-Net is used, and the decomposition of MRI images into multi-scale frequency components is done for extracting the spatial and spectral information related to brain abnormalities. For further refining the extracted features, the Adaptive Hiking Optimization algorithm (AHOA) is used, which selects the appropriate features and therein significantly mitigates the computational complexities and enhances the classification accuracy. The feature representation and non-linear patterns from the MRI images are utilized by the proposed QCNN for the classification. The benchmark OASIS dementia dataset attained an accuracy of 98%, and various parameters were analysed with the proposed QCNN. This ensures a highly accurate dementia classification with the proposed work.},
  keywords={Magnetic resonance imaging;Accuracy;Feature extraction;Convolutional neural networks;Electroencephalography;Diseases;Alzheimer's disease;Optimization;Classification algorithms;Deep learning;Adaptive hiking optimization algorithm;B-spline and Lanczos interpolation;quantum convolutional neural network;improved iHow optimization algorithm},
  doi={10.1109/ACCESS.2025.3598935},
  ISSN={2169-3536},
  month={},}@ARTICLE{9373391,
  author={He, Yuru and Cao, Shuangliang and Zhang, Hongyan and Sun, Hao and Wang, Fanghu and Zhu, Huobiao and Lv, Wenbing and Lu, Lijun},
  journal={IEEE Access}, 
  title={Dynamic PET Image Denoising With Deep Learning-Based Joint Filtering}, 
  year={2021},
  volume={9},
  number={},
  pages={41998-42012},
  abstract={Dynamic positron emission tomography (PET) imaging usually suffers from high statistical noise due to low counts of the short frames. This study aims to improve the image quality of the short frames by utilizing information from other modality. We develop a deep learning-based joint filtering framework for simultaneously incorporating information from longer acquisition PET frames and high-resolution magnetic resonance (MR) images into the short frames. The network inputs are noisy PET images and corresponding MR images while the outputs are linear coefficients of spatially variant linear representation model. The composite of all dynamic frames is used as training label in each sample, and it is down-sampled to 1/10th of counts as the training input. L1-norm combined with two gradient-based regularizations constitute the loss function during training. Ten realistic dynamic PET/MR phantoms based on BrainWeb are used for pre-training and eleven clinical subjects from Alzheimer's Disease Neuroimaging Initiative further for fine-tuning. Simulation results show that the proposed method can reduce the statistical noise while preserving image details and achieve quantitative enhancements compared with Gaussian, guided filter, and convolutional neural network trained with the mean squared error. The clinical results perform better than others in terms of the mean activity and standard deviation. All of the results indicate that the proposed deep learning-based joint filtering framework is of great potential for dynamic PET image denoising.},
  keywords={Positron emission tomography;Training;Convolution;Image edge detection;Nonlinear filters;Maximum likelihood detection;Artificial neural networks;Positron emission tomography;convolution neural network;denoising;spatially variant linear representation model;joint filtering},
  doi={10.1109/ACCESS.2021.3064926},
  ISSN={2169-3536},
  month={},}@ARTICLE{9870682,
  author={Huang, Huifang and Liu, Qian and Jiang, Yiqiao and Yang, Qingyu and Zhu, Xiaofeng and Li, Yang},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Deep Spatio-Temporal Attention-Based Recurrent Network From Dynamic Adaptive Functional Connectivity for MCI Identification}, 
  year={2022},
  volume={30},
  number={},
  pages={2600-2612},
  abstract={Most existing methods of constructing dynamic functional connectivity (dFC) network obtain the connectivity strength via the sliding window correlation (SWC) method, which estimates the connectivity strength at each time segment, rather than at each time point, and thus is difficult to produce accurate dFC network due to the influence of the window type and window width. Furthermore, the deep learning methods may not capture the discriminative spatio-temporal information that is closely related to disease, thus impacting the performance of mild cognitive impairment (MCI) identification. In this paper, a novel spatio-temporal attention-based bidirectional gated recurrent unit (STA-BiGRU) network is proposed to extract inherent spatio-temporal information from a dynamic adaptive functional connectivity (dAFC) network for MCI diagnosis. Specifically, we adopt a group lasso-based Kalman filter algorithm to obtain the dAFC network with more accurate connectivity strength at each time step. Then a spatial attention module with self-attention and a temporal attention module with multiple temporal attention vectors are incorporated into the BiGRU network to extract more discriminative disease-related spatio-temporal information. Finally, the spatio-temporal regularizations are employed to better guide the attention learning of STA-BiGRU network to enhance the robustness of the deep network. Experimental results show that the proposed framework achieves mean accuracies of 90.2%, 90.0%, and 81.5%, respectively, for three MCI classification tasks. This study provides a more effective deep spatio-temporal attention-based recurrent network and obtains good performance and interpretability of deep learning for psychiatry diagnosis research.},
  keywords={Data mining;Time series analysis;Heuristic algorithms;Feature extraction;Deep learning;Adaptive systems;Diseases;Dynamic adaptive functional connectivity (dAFC);computer aided analysis;attention;spatio-temporal information;functional MRI},
  doi={10.1109/TNSRE.2022.3202713},
  ISSN={1558-0210},
  month={},}@ARTICLE{10772278,
  author={Wu, Shuqiong and Noguchi, Tomoya and Okura, Fumio and Yagi, Yasushi},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Predicting Future Cognitive Decline From Long-Term Observations of Dual-Task Performance Data}, 
  year={2025},
  volume={29},
  number={2},
  pages={758-766},
  abstract={Early stage detection of cognitive decline is crucial for effective prevention and treatment of dementia. However, current approaches based on MRI or biomarkers are expensive and impractical, making them unsuitable for early-stage detection from daily measurements. A suitable option is the dual-task paradigm, which involves simultaneously performing two tasks (typically a physical task combined with a cognitive task). This approach has proven effective in assessing daily cognitive status. The underlying principle is that dual-task performance reflects the maximum cognitive load that can be handled by participants, which in turn reflects their current cognitive function. However, a one-time dual-task test cannot predict future changes in cognitive function. In this study, we present the first attempt at leveraging long-term observations of dual-task performance data. Our results show that changes in dual-task performance over time are associated with future cognitive changes. Our approach extracts temporal features from six months of dual-task performance data, and predicts future cognitive decline over the next two years using a machine learning model. Our experimental results yielded an accuracy comparable to that returned by MRI scans, thus demonstrating that the proposed approach can achieve early detection of future cognitive decline from routine dual-task measurements.},
  keywords={Dementia;Magnetic resonance imaging;Feature extraction;Biomedical measurement;Monitoring;Biomarkers;Bioinformatics;Pathology;Older adults;Data collection;Dual-task;dementia;MMSE;early-stage detection;mild cognitive impairment},
  doi={10.1109/JBHI.2024.3510064},
  ISSN={2168-2208},
  month={Feb},}@ARTICLE{9311169,
  author={Mohammadi, Sara Mahvash and Enshaeifar, Shirin and Hilton, Adrian and Dijk, Derk-Jan and Wells, Kevin},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Transfer Learning for Clinical Sleep Pose Detection Using a Single 2D IR Camera}, 
  year={2021},
  volume={29},
  number={},
  pages={290-299},
  abstract={Sleep quality is an important determinant of human health and wellbeing. Novel technologies that can quantify sleep quality at scale are required to enable the diagnosis and epidemiology of poor sleep. One important indicator of sleep quality is body posture. In this paper, we present the design and implementation of a non-contact sleep monitoring system that analyses body posture and movement. Supervised machine learning strategies applied to noncontact vision-based infrared camera data using a transfer learning approach, successfully quantified sleep poses of participants covered by a blanket. This represents the first occasion that such a machine learning approach has been used to successfully detect four predefined poses and the empty bed state during 8-10 hour overnight sleep episodes representing a realistic domestic sleep situation. The methodology was evaluated against manually scored sleep poses and poses estimated using clinical polysomnography measurement technology. In a cohort of 12 healthy participants, we find that a ResNet-152 pre-trained network achieved the best performance compared with the standard de novo CNN network and other pre-trained networks. The performance of our approach was better than other video-based methods for sleep pose estimation and produced higher performance compared to the clinical standard for pose estimation using a polysomnography position sensor. It can be concluded that infrared video capture coupled with deep learning AI can be successfully used to quantify sleep poses as well as the transitions between poses in realistic nocturnal conditions, and that this non-contact approach provides superior pose estimation compared to currently accepted clinical methods.},
  keywords={Sleep;Cameras;Standards;Monitoring;Pose estimation;Manuals;Feature extraction;Pose detection;convolutional neural networks (CNN);sleep;transfer learning;polysomnography (PSG)},
  doi={10.1109/TNSRE.2020.3048121},
  ISSN={1558-0210},
  month={},}@ARTICLE{10323307,
  author={Vekkot, Susmitha and Prakash, Nagulapati Naga Venkata Sai and Reddy, Thirupati Sai Eswar and Sripathi, Satwik Reddy and Lalitha, S. and Gupta, Deepa and Zakariah, Mohammed and Alotaibi, Yousef Ajami},
  journal={IEEE Access}, 
  title={Dementia Speech Dataset Creation and Analysis in Indic Languages—A Pilot Study}, 
  year={2023},
  volume={11},
  number={},
  pages={130697-130718},
  abstract={The paper describes the creation, analysis and validation of a multilingual Dementia Speech dataset for Indic languages. Three popular Indian languages viz. Telugu, Tamil and Hindi are considered for the pilot study. Dementia and associated Alzheimers disease affect a large section of Asian population. Though there are promising studies in dementia detection focussed on Western ethnicity, the absence of a clinical dementia dataset for Indian languages forms the primary motivation for this study. This pilot study aims to overcome the challenges associated with data collection and validation in a clinical setting and deal with situations wherein clinical data is not readily available. The Indic dementia dataset is an enacted non-clinical dataset created from the manual translations of the benchmark clinical English DementiaBank dataset. The dataset created is validated using features extracted from the benchmark. The feature evaluation revealed a similarity of 92.6% for silences, 92% for mean pitch (Hz), 84.7% for jitter and 90.3% for shimmer. Subjective evaluation was also conducted based on clarity and similarity of utterances with DementiaBank data. An average MOS of 3.9 for clarity of speech and 3.76 for similarity with respect to DementiaBank was obtained across all three languages. A baseline classification using state-of-art deep network architecture gave a maximum of 78% accuracy in dementia detection using the Indic dementia dataset. The pilot experimentation in this work gives promising insights into the development of a multilingual dataset for analysis of clinical speech patterns in early dementia in the Indian population.},
  keywords={Alzheimer's disease;Statistics;Sociology;Recording;Feature extraction;Sensitivity;Older adults;Dementia;Jitter;Speech processing;Dementia;Indic speech;pitch;silences;jitter;shimmer;Pearson correlation;cosine similarity},
  doi={10.1109/ACCESS.2023.3334790},
  ISSN={2169-3536},
  month={},}@ARTICLE{9121705,
  author={Muslu, Özlem and Hoyt, Charles Tapley and Lacerda, Mauricio and Hofmann-Apitius, Martin and Fröhlich, Holger},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={GuiltyTargets: Prioritization of Novel Therapeutic Targets With Network Representation Learning}, 
  year={2022},
  volume={19},
  number={1},
  pages={491-500},
  abstract={The majority of clinical trials fail due to low efficacy of investigated drugs, often resulting from a poor choice of target protein. Existing computational approaches aim to support target selection either via genetic evidence or by putting potential targets into the context of a disease specific network reconstruction. The purpose of this work was to investigate whether network representation learning techniques could be used to allow for a machine learning based prioritization of putative targets. We propose a novel target prioritization approach, GuiltyTargets, which relies on attributed network representation learning of a genome-wide protein-protein interaction network annotated with disease-specific differential gene expression and uses positive-unlabeled (PU) machine learning for candidate ranking. We evaluated our approach on 12 datasets from six diseases of different type (cancer, metabolic, neurodegenerative) within a 10 times repeated 5-fold stratified cross-validation and achieved AUROC values between 0.92 - 0.97, significantly outperforming previous approaches that relied on manually engineered topological features. Moreover, we showed that GuiltyTargets allows for target repositioning across related disease areas. An application of GuiltyTargets to Alzheimer’s disease resulted in a number of highly ranked candidates that are currently discussed as targets in the literature. Interestingly, one (COMT) is also the target of an approved drug (Tolcapone) for Parkinson’s disease, highlighting the potential for target repositioning with our method. The GuiltyTargets Python package is available on PyPI and all code used for analysis can be found under the MIT License at https://github.com/GuiltyTargets. Attributed network representation learning techniques provide an interesting approach to effectively leverage the existing knowledge about the molecular mechanisms in different diseases. In this work, the combination with positive-unlabeled learning for target prioritization demonstrated a clear superiority compared to classical feature engineering approaches. Our work highlights the potential of attributed network representation learning for target prioritization. Given the overarching relevance of networks in computational biology we believe that attributed network representation learning techniques could have a broader impact in the future.},
  keywords={Proteins;Diseases;Drugs;Bioinformatics;Machine learning;Gene expression;Logistics;Artificial intelligence;neural networks;bioinformatics},
  doi={10.1109/TCBB.2020.3003830},
  ISSN={1557-9964},
  month={Jan},}@ARTICLE{11075686,
  author={Li, Juan and Zhang, Dongyuan and Lin, Wei and Liu, Wei},
  journal={IEEE Access}, 
  title={Using EEG Signals and AI to Predict Neurodegenerative Diseases}, 
  year={2025},
  volume={13},
  number={},
  pages={128879-128894},
  abstract={Diseases like Alzheimer’s and Parkinson’s pose significant challenges because of their complex and progressive characteristics. Addressing these conditions requires advanced diagnostic methods that support value-based care. This study proposes NeuroPredictNet, a deep learning-based predictive framework designed for early and accurate disease identification. NeuroPredictNet integrates multimodal data—EEG, neuroimaging, genetic, and clinical features—through an attention-based fusion mechanism that dynamically weights modality contributions. We introduce the Adaptive Knowledge Integration Strategy (AKIS) to enhance model robustness by addressing modality-specific noise, data imbalance, and temporal consistency. Experimental evaluations on four benchmark datasets demonstrate that our method achieves superior prediction accuracy and interpretability compared to state-of-the-art approaches. These results underscore the framework’s clinical potential in supporting personalized, value-based neurological care.},
  keywords={Electroencephalography;Diseases;Brain modeling;Predictive models;Feature extraction;Accuracy;Deep learning;Artificial intelligence;Transformers;Genetics;Neurodegenerative disease prediction;deep learning;multimodal data fusion;attention mechanism;EEG analysis;adaptive knowledge integration;temporal modeling;explainable AI},
  doi={10.1109/ACCESS.2025.3586363},
  ISSN={2169-3536},
  month={},}@ARTICLE{8949485,
  author={Kang, Jiayin and Lu, Wu and Zhang, Wenjuan},
  journal={IEEE Access}, 
  title={Fusion of Brain PET and MRI Images Using Tissue-Aware Conditional Generative Adversarial Network With Joint Loss}, 
  year={2020},
  volume={8},
  number={},
  pages={6368-6378},
  abstract={Positron emission tomography (PET) has rich pseudo color information that reflects the functional characteristics of tissue, but lacks structural information and its spatial resolution is low. Magnetic resonance imaging (MRI) has high spatial resolution as well as strong structural information of soft tissue, but lacks color information that shows the functional characteristics of tissue. For the purpose of integrating the color information of PET with the anatomical structures of MRI to help doctors diagnose diseases better, a method for fusing brain PET and MRI images using tissue-aware conditional generative adversarial network (TA-cGAN) is proposed. Specifically, the process of fusing brain PET and MRI images is treated as an adversarial machine between retaining the color information of PET and preserving the anatomical information of MRI. More specifically, the fusion of PET and MRI images can be regarded as a min-max optimization problem with respect to the generator and the discriminator, where the generator attempts to minimize the objective function via generating a fused image mainly contains the color information of PET, whereas the discriminator tries to maximize the objective function through urging the fused image to include more structural information of MRI. Both the generator and the discriminator in TA-cGAN are conditioned on the tissue label map generated from MRI image, and are trained alternatively with joint loss. Extensive experiments demonstrate that the proposed method enhances the anatomical details of the fused image while effectively preserving the color information from the PET. In addition, compared with other state-of-the-art methods, the proposed method achieves better fusion effects both in subjectively visual perception and in objectively quantitative assessment.},
  keywords={Magnetic resonance imaging;Generative adversarial networks;Positron emission tomography;Image color analysis;Generators;Image fusion;Gallium nitride;Positron emission tomography;magnetic resonance imaging;image fusion;generative adversarial network;loss function},
  doi={10.1109/ACCESS.2019.2963741},
  ISSN={2169-3536},
  month={},}@ARTICLE{9051819,
  author={Cao, Ping and Sheng, Qiuyang and Fang, Siqi and Li, Xinyi and Ning, Gangmin and Pan, Qing},
  journal={IEEE Access}, 
  title={Fusion of Multi-Size Candidate Regions Enhances Two-Stage Hippocampus Segmentation}, 
  year={2020},
  volume={8},
  number={},
  pages={63225-63238},
  abstract={The hippocampus plays an important role in the memory and cognition abilities of humans. Precise three-dimensional (3D) segmentation of the hippocampus from magnetic resonance imaging scans is of great importance in the diagnosis of neurological diseases. Conventional automatic segmentation methods poorly achieve satisfactory performance because of the irregular shape and small volume of the hippocampus. We propose a novel two-stage segmentation method, which includes a localization stage and a segmentation stage, to handle the task of the 3D segmentation of the hippocampus. In the localization stage, a novel strategy for localizing multi-size candidate regions was developed to improve the sample balance for the 3D segmentation task. In the segmentation stage, a method which fuses the multi-size candidate regions was proposed to improve the accuracy in predicting the hippocampal boundary, after which we aggregated the segmentation results from three orthogonal views to further improve the performance. Quantitative evaluation was performed on the Alzheimer's Disease Neuroimaging Initiative dataset. The experimental results achieved Dice similarity coefficients of 92.48 ± 0.61% and 92.90 ± 0.51% for the left and right hippocampus, respectively, outperforming state-of-the-art studies in hippocampus segmentation tasks.},
  keywords={Hippocampus;Image segmentation;Three-dimensional displays;Magnetic resonance imaging;Task analysis;Two dimensional displays;Morphology;Hippocampus segmentation;hippocampus localization;fully convolutional network;two-stage segmentation},
  doi={10.1109/ACCESS.2020.2984661},
  ISSN={2169-3536},
  month={},}@ARTICLE{11000331,
  author={Riviera, Walter and Galazzo, Ilaria Boscolo and Menegaz, Gloria},
  journal={IEEE Access}, 
  title={FLavourite: Horizontal and Vertical Federated Learning Setting Comparison}, 
  year={2025},
  volume={13},
  number={},
  pages={86588-86598},
  abstract={Federated learning (FL) enables multiple organizations to collaboratively train AI models while keeping data separate. Depending on data distribution, FL can be set up horizontally (HFL) or vertically (VFL). When multi-modal data are already available in the same infrastructure, the choice of FL setting depends on the workload needs, such as level of privacy, evaluation metrics, and time-to-train. In this paper, we perform a qualitative and extensive evaluation of the HFL and VFL settings to provide guidance on how to choose a specific setting based on workload needs. We assess the classification of Alzheimer’s disease using non-independent and identically distributed (non-i.i.d.) 3D images and tabular data. The results demonstrate how, with the same aggregation function, HFL converges faster to higher accuracy and f1-score than VFL and demonstrate how HFL can be further improved due to a more flexible architecture. Finally, we provide practical considerations on when to choose which setting and share the implementations of the pipelines for reproducibility.},
  keywords={Data models;Distributed databases;Pipelines;Federated learning;Computer architecture;Biological system modeling;Hospitals;Training;Three-dimensional displays;Computational modeling;Federated learning;vertical FL;horizontal FL;federated average;aggregation functions},
  doi={10.1109/ACCESS.2025.3569158},
  ISSN={2169-3536},
  month={},}@ARTICLE{9729447,
  author={Wang, Lei and Li, Hao and Wang, Yuqi and Tan, Yihong and Chen, Zhiping and Pei, Tingrui and Zou, Quan},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={MDADP: A Webserver Integrating Database and Prediction Tools for Microbe-Disease Associations}, 
  year={2022},
  volume={26},
  number={7},
  pages={3427-3434},
  abstract={More and more evidence has demonstrated that microbiota play important roles in the life processes of the human body. In recent years, various computational methods have been proposed for identifying potentially disease-associated microbes to save costs in traditional biological experiments. However, prediction performances of these methods are generally limited by outdated and incomplete datasets. And moreover, until now, there are limited studies that can provide visual predictive tools for inferring possible microbe-disease associations (MDAs) as well. Hence, in this manuscript, a novel webserver called MDADP will be proposed to identify latent MDAs, in which, a new MDA database together with interactive prediction tools for MDAs studies will be designed simultaneously. Especially, in the newly constructed MDA database, 2019 known MDAs between 58 diseases and 703 microbes have been manually collected first. And then, through adopting the average ranking method and the co-confidence method respectively, eight representative computational models have been integrated together to identify potential disease-related microbes. As a result, MDADP can provide not only interactive features for users to access and capture MDAs entities, but alsoeffective tools for users to identify candidate microbes for different diseases. To our knowledge, MDADP is the first online platform that incorporates a new MDA database with comprehensive MDA prediction tools. Therefore, we believe that it will be a valuable source of information for researches in microbiology and disease-related fields. MDADP can be accessed at http://mdadp.leelab2997.cn.},
  keywords={Diseases;Databases;Computational modeling;Predictive models;Analytical models;Biological system modeling;Bioinformatics;Association database;association prediction tool;disease;microbe},
  doi={10.1109/JBHI.2022.3156166},
  ISSN={2168-2208},
  month={July},}@ARTICLE{9684388,
  author={Khan, Shehroz S. and Mishra, Pratik K. and Javed, Nizwa and Ye, Bing and Newman, Kristine and Mihailidis, Alex and Iaboni, Andrea},
  journal={IEEE Access}, 
  title={Unsupervised Deep Learning to Detect Agitation From Videos in People With Dementia}, 
  year={2022},
  volume={10},
  number={},
  pages={10349-10358},
  abstract={Behavioural symptoms of dementia present a significant risk within Long Term Care (LTC) homes, which face difficulties supporting residents and monitoring their safety with limited staffing resources. Many LTC facilities have installed video surveillance systems in common areas that can help staff to observe residents; however, typically these video streams are not monitored. In this paper, we present the development of a computer vision algorithm to use these video streams to detect episodes of clinically important agitation in people with dementia. Given that episodes of agitation are rare in comparison to normal behaviours, we formulated this as an anomaly detection problem. This involves using the video camera to monitor the scene rather than tracking individuals. We developed a customized spatio-temporal convolution autoencoder that is trained on the normal behaviours and then identified agitation during testing as anomalous behaviour. We present a proof-of-concept using video data collected from a specialized dementia unit and annotated for agitation events. We trained the unsupervised neural network on approximately 24 hours of normal activities and tested on 11 hours of videos containing both normal activities and agitation events, and obtained an area under the curve of the receiver operating characteristic curve of 0.754. This research paves the way for leveraging existing surveillance infrastructure in LTC and other mental health settings to detect agitation or aggression, with the potential for improved health and safety.},
  keywords={Dementia;Cameras;Deep learning;Training;Monitoring;Image reconstruction;Anomaly detection;Dementia;agitation;camera;long term care;autoencoder;deep learning;computer vision},
  doi={10.1109/ACCESS.2022.3143990},
  ISSN={2169-3536},
  month={},}@ARTICLE{10504255,
  author={Hammour, Ghena and Davies, Harry and Atzori, Giuseppe and Della Monica, Ciro and Ravindran, Kiran K. G. and Revell, Victoria and Dijk, Derk-Jan and Mandic, Danilo P.},
  journal={IEEE Journal of Translational Engineering in Health and Medicine}, 
  title={From Scalp to Ear-EEG: A Generalizable Transfer Learning Model for Automatic Sleep Scoring in Older People}, 
  year={2024},
  volume={12},
  number={},
  pages={448-456},
  abstract={Objective: Sleep monitoring has extensively utilized electroencephalogram (EEG) data collected from the scalp, yielding very large data repositories and well-trained analysis models. Yet, this wealth of data is lacking for emerging, less intrusive modalities, such as ear-EEG.Methods and procedures: The current study seeks to harness the abundance of open-source scalp EEG datasets by applying models pre-trained on data, either directly or with minimal fine-tuning; this is achieved in the context of effective sleep analysis from ear-EEG data that was recorded using a single in-ear electrode, referenced to the ipsilateral mastoid, and developed in-house as described in our previous work. Unlike previous studies, our research uniquely focuses on an older cohort (17 subjects aged 65-83, mean age 71.8 years, some with health conditions), and employs LightGBM for transfer learning, diverging from previous deep learning approaches. Results: Results show that the initial accuracy of the pre-trained model on ear-EEG was 70.1%, but fine-tuning the model with ear-EEG data improved its classification accuracy to 73.7%. The fine-tuned model exhibited a statistically significant improvement (p < 0.05, dependent t-test) for 10 out of the 13 participants, as reflected by an enhanced average Cohen’s kappa score (a statistical measure of inter-rater agreement for categorical items) of 0.639, indicating a stronger agreement between automated and expert classifications of sleep stages. Comparative SHAP value analysis revealed a shift in feature importance for the N3 sleep stage, underscoring the effectiveness of the fine-tuning process.Conclusion: Our findings underscore the potential of fine-tuning pre-trained scalp EEG models on ear-EEG data to enhance classification accuracy, particularly within an older population and using feature-based methods for transfer learning. This approach presents a promising avenue for ear-EEG analysis in sleep studies, offering new insights into the applicability of transfer learning across different populations and computational techniques.Clinical impact: An enhanced ear-EEG method could be pivotal in remote monitoring settings, allowing for continuous, non-invasive sleep quality assessment in elderly patients with conditions like dementia or sleep apnea.},
  keywords={Sleep;Electroencephalography;Brain modeling;Data models;Scalp;Recording;Sensors;Automatic sleep scoring;hearables;ear-EEG;machine learning;wearable EEG},
  doi={10.1109/JTEHM.2024.3388852},
  ISSN={2168-2372},
  month={},}@ARTICLE{9693495,
  author={Alkuhlani, Alhasan and Gad, Walaa and Roushdy, Mohamed and Salem, Abdel-Badeeh M.},
  journal={IEEE Access}, 
  title={PUStackNGly: Positive-Unlabeled and Stacking Learning for N-Linked Glycosylation Site Prediction}, 
  year={2022},
  volume={10},
  number={},
  pages={12702-12713},
  abstract={N-linked glycosylation is one of the most common protein post-translation modifications (PTMs) in humans where the Asparagine (N) amino acid of the protein is attached to the glycan. It is involved in most biological processes and associated with various human diseases as diabetes, cancer, coronavirus, influenza, and Alzheimer’s. Accordingly, identifying N-linked glycosylation sites will be beneficial to understanding the system and mechanism of glycosylation. Due to the experimental challenges of glycosylation site identification, machine learning becomes very important to predict the glycosylation sites. This paper proposes a novel N-linked glycosylation predictor based on bagging positive-unlabeled (PU) learning and stacking ensemble machine learning (PUStackNGly). In the proposed PUStackNGly, comprehensive sequence and structural-based features are extracted using different feature extraction descriptors. Then, ensemble-based feature selection is employed to select the most significant and stable features. The ensemble bagging PU learning selects the reliable negative samples from the unlabeled samples using four supervised learning methods (support vector machines, random forest, logistic regression, and XGBoost). Then, stacking ensemble learning is applied using four base classifiers: logistic regression, artificial neural networks, random forest, and support vector machine. The experiments results show that PUStackNGly has a promising predicting performance compared to supervised learning methods. Furthermore, the proposed PUStackNgly outperforms the existing N-linked glycosylation prediction tools on an independent dataset with 95.11% accuracy, 100% recall 80.7% precision, 89.32% F1 score, 96.93% AUC, and 0.87 MCC.},
  keywords={Feature extraction;Support vector machines;Amino acids;Peptides;Stacking;Machine learning;Proteins;Glycosylation;glycosylation sites prediction;machine learning;positive-unlabeled learning;stacking ensemble learning},
  doi={10.1109/ACCESS.2022.3146395},
  ISSN={2169-3536},
  month={},}@ARTICLE{9388697,
  author={Sun, Hao and Peng, Lihong and Zhang, Hongyan and He, Yuru and Cao, Shuangliang and Lu, Lijun},
  journal={IEEE Access}, 
  title={Dynamic PET Image Denoising Using Deep Image Prior Combined With Regularization by Denoising}, 
  year={2021},
  volume={9},
  number={},
  pages={52378-52392},
  abstract={The quantitative accuracy of positron emission tomography (PET) is affected by several factors, including the intrinsic resolution of the imaging system and inherently noisy data, which result in a low signal-to-noise ratio (SNR) of PET image. To address this problem, in this paper, we proposed a novel deep learning denoising framework aiming to enhance the quantitative accuracy of dynamic PET images via introduction of deep image prior (DIP) combined with Regularization by Denoising (RED), as such the method is labeled as DeepRED denoising. The network structure is based on encoder-decoder architecture and uses skip connections to combine hierarchical features to generate the estimated image. The network input can be random noise or other prior images (such as the patient's own static PET image), avoiding the need of high quality noiseless images, which is limited in PET clinical practice due to high radiation dose. Based on simulated data and real patient data, the quantitative performance of the proposed method was compared with conventional Gaussian filtering (GF), non-local mean (NLM), block-matching and 3D filtering (BM3D), DIP and stochastic gradient Langevin dynamics (SGLD) method. Overall, the proposed method can outperform other conventional methods in substantial visual as well as quantitative accuracy improvements (in terms of noise versus bias performance) with and without prior images.},
  keywords={Positron emission tomography;Electronics packaging;Noise reduction;Imaging;Image segmentation;Filtering;Training;Positron emission tomography;deep neural networks;deep image prior;regularization by denoising},
  doi={10.1109/ACCESS.2021.3069236},
  ISSN={2169-3536},
  month={},}@ARTICLE{9043495,
  author={Zeng, Xianhua and Tong, Shiyue and Lu, Yuzhe and Xu, Liming and Huang, Zhiwei},
  journal={IEEE Access}, 
  title={Adaptive Medical Image Deep Color Perception Algorithm}, 
  year={2020},
  volume={8},
  number={},
  pages={56559-56571},
  abstract={The existing medical imaging technologies have little consideration on color information, thus most of medical images are gray. Classical hand-craft features-based methods have obtained unsatisfactory results in colorizing medical images. Moreover, these methods ignore the deep feature of medical images that represent pathology and color information. In this paper, we propose a novel method that iteratively colorizes grayscale medical images under preserving content in fine-tuned deep neural network. To the best of our knowledge, there is no currently work that attempts to colorize the medical image by using deep neural network. Specifically, we propose Y-loss which is defined as nonlinear combination of ℓ1 and ℓ2 norm to preserve content invariance between target and colorized medical image. Then, adaptive reference image search algorithm is introduced to code reference and target medical image with D-hash and search reference image in hash code automatically, which free the manual selection of the reference image. Extensive experiment results show that the proposed method can generate higher quality colored medical image than recent state-of-the-art methods, and can be approved by the doctor. The objective evaluation (PSNR and SSIM) outperform an average increment 24% and 47% than baseline method, respectively. Our code is available at: https://github.com/Tongshiyue/Adaptive-medical-image-deep-color-perception-algorithm.},
  keywords={Image color analysis;Medical diagnostic imaging;Feature extraction;Medical services;Neural networks;Gray-scale;Medical images enhance;color images;color transfer;deep neural network;automatic search},
  doi={10.1109/ACCESS.2020.2982187},
  ISSN={2169-3536},
  month={},}
